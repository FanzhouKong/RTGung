{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import time\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import toolsets.feature_engineering as fe\n",
    "import toolsets.data_prep as data_prep\n",
    "import toolsets.auto_rt_pred as ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "descriptors = pd.read_csv(\"data/multiRT/MultiRT_hilic_descriptors.csv\", low_memory=False)\n",
    "combined_data = pd.read_csv(\"data/multiRT/Combined dataset.csv\")\n",
    "hilic = combined_data.loc[combined_data['Column']=='HILIC']\n",
    "hilic.reset_index(inplace=True, drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "\n",
    "SEED = 123456\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the running time for mice is 20.327151203155516\n"
     ]
    }
   ],
   "source": [
    "# imputing missing descriptors\n",
    "features_imp = fe.missing_descriptors_imputation(descriptors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "data = pd.concat([hilic, features_imp], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "data= data_prep.dataset_prep(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k-fold: 100%|██████████| 100/100 [01:58<00:00,  1.18s/it]\n",
      "k-fold: 100%|██████████| 100/100 [01:59<00:00,  1.20s/it]\n"
     ]
    }
   ],
   "source": [
    "# this is trying to use a feature subset for excluding mislabeled data; please pass a valid categorical column as second parameter; if you dont have 1 you can just make a new categorical column; the demo version use column Organic_modifier\n",
    "data_confirmed = fe.mislable_exclusion(data, 'Organic_modifier', features_imp.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# convert categorical to dummies\n",
    "data_confirmed = fe.make_dummies(data_confirmed,['Buffer', 'Organic_modifier', 'Column'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# drop some useless columns\n",
    "data_confirmed =data_confirmed.drop(['Compound_name', 'SMILES'],axis = 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train, test = data_prep.make_train_test(data_confirmed)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"finalized\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"finalized/\"\n",
      "AutoGluon Version:  0.4.1b20220423\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    635\n",
      "Train Data Columns: 1513\n",
      "Label Column: retention_time\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.357142857142858, 1.0871428571428572, 2.44968, 1.39653)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4267.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.21 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 60 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 198): ['nBridgehead', 'nB', 'nBr', 'nI', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NssssN', 'NaaO', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SssssN', 'SaaO', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'ETA_dPsi_B', 'SMR_VSA8', 'SlogP_VSA9', 'n4Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n4ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n11FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n11FHRing', 'n12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n11FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n11FAHRing', 'n12FAHRing', 'MAXdCH2', 'MAXtCH', 'MAXsSH', 'MAXaaS', 'MAXdssS', 'MINdCH2', 'MINtCH', 'MINsSH', 'MINaaS', 'MINdssS', 'split_index']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1176 | ['pH', 'ABC', 'ABCGG', 'SpAbs_A', 'SpMax_A', ...]\n",
      "\t\t('int', [])   :  139 | ['nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 1165 | ['pH', 'ABC', 'ABCGG', 'SpAbs_A', 'SpMax_A', ...]\n",
      "\t\t('int', [])       :   90 | ['nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', ...]\n",
      "\t\t('int', ['bool']) :   60 | ['nSpiro', 'nP', 'nBondsT', 'C1SP1', 'Xch-3d', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t1315 features in original data used to generate 1315 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.98 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.79s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 508, Val Rows: 127\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.7922\t = Validation score   (root_mean_squared_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.147\t = Validation score   (root_mean_squared_error)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.4466\t = Validation score   (root_mean_squared_error)\n",
      "\t14.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.4691\t = Validation score   (root_mean_squared_error)\n",
      "\t23.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.395\t = Validation score   (root_mean_squared_error)\n",
      "\t5.41s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.398\t = Validation score   (root_mean_squared_error)\n",
      "\t6.3s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.3975\t = Validation score   (root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training (ImportError)... Skipping this model.\n",
      "\t\tImport fastai failed. A quick tip is to install via `pip install fastai==2.*`. If you are using Mac OSX, please use this torch version to avoid compatibility issues: `pip install torch==1.6.0`.\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.3903\t = Validation score   (root_mean_squared_error)\n",
      "\t8.78s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.7419\t = Validation score   (root_mean_squared_error)\n",
      "\t4.71s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.3852\t = Validation score   (root_mean_squared_error)\n",
      "\t23.56s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.3747\t = Validation score   (root_mean_squared_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 90.12s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"finalized/\")\n",
      "Evaluation: root_mean_squared_error on test data: -0.38105503978559235\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.38105503978559235,\n",
      "    \"mean_squared_error\": -0.14520294334599937,\n",
      "    \"mean_absolute_error\": -0.1721907245113206,\n",
      "    \"r2\": 0.9147318391468239,\n",
      "    \"pearsonr\": 0.9576439923486171,\n",
      "    \"median_absolute_error\": -0.036705640384129046\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -0.374683       0.141819  37.135914                0.000146           0.083173            2       True         11\n",
      "1         LightGBMLarge  -0.385187       0.004336  23.562688                0.004336          23.562688            1       True         10\n",
      "2               XGBoost  -0.390255       0.007525   8.780650                0.007525           8.780650            1       True          8\n",
      "3       RandomForestMSE  -0.394996       0.018778   5.413740                0.018778           5.413740            1       True          5\n",
      "4         ExtraTreesMSE  -0.397499       0.018449   1.799263                0.018449           1.799263            1       True          7\n",
      "5              CatBoost  -0.398034       0.012736   6.302033                0.012736           6.302033            1       True          6\n",
      "6            LightGBMXT  -0.446556       0.004276  14.435720                0.004276          14.435720            1       True          3\n",
      "7              LightGBM  -0.469050       0.007394  23.073487                0.007394          23.073487            1       True          4\n",
      "8        NeuralNetTorch  -0.741917       0.129812   4.709403                0.129812           4.709403            1       True          9\n",
      "9        KNeighborsUnif  -0.792175       0.020575   0.070663                0.020575           0.070663            1       True          1\n",
      "10       KNeighborsDist  -1.147016       0.034971   0.128947                0.034971           0.128947            1       True          2\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'XGBoostModel', 'TabularNeuralNetTorchModel', 'WeightedEnsembleModel', 'LGBModel', 'KNNModel', 'RFModel', 'CatBoostModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('float', [])     : 1165 | ['pH', 'ABC', 'ABCGG', 'SpAbs_A', 'SpMax_A', ...]\n",
      "('int', [])       :   90 | ['nAcid', 'nBase', 'nAromAtom', 'nAromBond', 'nAtom', ...]\n",
      "('int', ['bool']) :   60 | ['nSpiro', 'nP', 'nBondsT', 'C1SP1', 'Xch-3d', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'CatBoost': 'CatBoostModel', 'ExtraTreesMSE': 'XTModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -0.792174529393286, 'KNeighborsDist': -1.1470160694400728, 'LightGBMXT': -0.4465558078979418, 'LightGBM': -0.4690501235568685, 'RandomForestMSE': -0.3949963704651345, 'CatBoost': -0.39803403184176855, 'ExtraTreesMSE': -0.3974991967836094, 'XGBoost': -0.39025475073619875, 'NeuralNetTorch': -0.7419166822215855, 'LightGBMLarge': -0.3851870558494747, 'WeightedEnsemble_L2': -0.3746826983853912}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': 'finalized/models/KNeighborsUnif/', 'KNeighborsDist': 'finalized/models/KNeighborsDist/', 'LightGBMXT': 'finalized/models/LightGBMXT/', 'LightGBM': 'finalized/models/LightGBM/', 'RandomForestMSE': 'finalized/models/RandomForestMSE/', 'CatBoost': 'finalized/models/CatBoost/', 'ExtraTreesMSE': 'finalized/models/ExtraTreesMSE/', 'XGBoost': 'finalized/models/XGBoost/', 'NeuralNetTorch': 'finalized/models/NeuralNetTorch/', 'LightGBMLarge': 'finalized/models/LightGBMLarge/', 'WeightedEnsemble_L2': 'finalized/models/WeightedEnsemble_L2/'}, 'model_fit_times': {'KNeighborsUnif': 0.0706629753112793, 'KNeighborsDist': 0.12894701957702637, 'LightGBMXT': 14.435719966888428, 'LightGBM': 23.073487043380737, 'RandomForestMSE': 5.413739919662476, 'CatBoost': 6.302032947540283, 'ExtraTreesMSE': 1.7992627620697021, 'XGBoost': 8.780649900436401, 'NeuralNetTorch': 4.709403038024902, 'LightGBMLarge': 23.56268811225891, 'WeightedEnsemble_L2': 0.08317303657531738}, 'model_pred_times': {'KNeighborsUnif': 0.02057480812072754, 'KNeighborsDist': 0.034970998764038086, 'LightGBMXT': 0.0042760372161865234, 'LightGBM': 0.007394075393676758, 'RandomForestMSE': 0.018778085708618164, 'CatBoost': 0.012735843658447266, 'ExtraTreesMSE': 0.018449068069458008, 'XGBoost': 0.007524967193603516, 'NeuralNetTorch': 0.12981176376342773, 'LightGBMLarge': 0.004335880279541016, 'WeightedEnsemble_L2': 0.00014591217041015625}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'CatBoost': {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}, 'ExtraTreesMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val   fit_time  \\\n",
      "0   WeightedEnsemble_L2  -0.374683       0.141819  37.135914   \n",
      "1         LightGBMLarge  -0.385187       0.004336  23.562688   \n",
      "2               XGBoost  -0.390255       0.007525   8.780650   \n",
      "3       RandomForestMSE  -0.394996       0.018778   5.413740   \n",
      "4         ExtraTreesMSE  -0.397499       0.018449   1.799263   \n",
      "5              CatBoost  -0.398034       0.012736   6.302033   \n",
      "6            LightGBMXT  -0.446556       0.004276  14.435720   \n",
      "7              LightGBM  -0.469050       0.007394  23.073487   \n",
      "8        NeuralNetTorch  -0.741917       0.129812   4.709403   \n",
      "9        KNeighborsUnif  -0.792175       0.020575   0.070663   \n",
      "10       KNeighborsDist  -1.147016       0.034971   0.128947   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000146           0.083173            2       True   \n",
      "1                 0.004336          23.562688            1       True   \n",
      "2                 0.007525           8.780650            1       True   \n",
      "3                 0.018778           5.413740            1       True   \n",
      "4                 0.018449           1.799263            1       True   \n",
      "5                 0.012736           6.302033            1       True   \n",
      "6                 0.004276          14.435720            1       True   \n",
      "7                 0.007394          23.073487            1       True   \n",
      "8                 0.129812           4.709403            1       True   \n",
      "9                 0.020575           0.070663            1       True   \n",
      "10                0.034971           0.128947            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          11  \n",
      "1          10  \n",
      "2           8  \n",
      "3           5  \n",
      "4           7  \n",
      "5           6  \n",
      "6           3  \n",
      "7           4  \n",
      "8           9  \n",
      "9           1  \n",
      "10          2  }\n",
      "{'root_mean_squared_error': -0.38105503978559235, 'mean_squared_error': -0.14520294334599937, 'mean_absolute_error': -0.1721907245113206, 'r2': 0.9147318391468239, 'pearsonr': 0.9576439923486171, 'median_absolute_error': -0.036705640384129046}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x28dc1dcd0>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting with autogluon, third parameter use as save model name\n",
    "ap.autogluon_fit_train_test(train,test, \"finalized\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.9 (tensorflow)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}