{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import toolsets.auto_rt_pred as auto_fit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toolsets.data_prep as dp\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "data = pd.read_csv(\"data/multiRT/Combined dataset.csv\")\n",
    "# data_hilic = data.loc[data['Column'] == 'HILIC']\n",
    "# data_hilic.head()\n",
    "descriptors = pd.read_csv(\"data/multiRT/MultiRT_hilic_descriptors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "836"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "data_hilic = data.loc[data['Column']=='HILIC']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "data_hilic = dp.dataset_prep(data_hilic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "data_hilic = dp.make_split_index(data_hilic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "data_hilic = data_hilic.drop(['Compound_name'], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "data": {
      "text/plain": "     Column Organic_modifier   pH       Buffer  \\\n22    HILIC     Acetonitrile  2.7  Formic acid   \n23    HILIC     Acetonitrile  3.0  Acetic acid   \n24    HILIC     Acetonitrile  3.0  Formic acid   \n25    HILIC     Acetonitrile  5.0  Acetic acid   \n26    HILIC     Acetonitrile  5.0  Formic acid   \n...     ...              ...  ...          ...   \n2956  HILIC     Acetonitrile  5.0  Formic acid   \n2957  HILIC         Methanol  2.7  Formic acid   \n2958  HILIC         Methanol  3.0  Formic acid   \n2959  HILIC         Methanol  5.0  Acetic acid   \n2960  HILIC         Methanol  5.0  Formic acid   \n\n                                                 SMILES  retention_time  \\\n22                        c1cc2ccc3ccc(c4ccc(c1)c2c34)O        1.822857   \n23                        c1cc2ccc3ccc(c4ccc(c1)c2c34)O       12.321429   \n24                        c1cc2ccc3ccc(c4ccc(c1)c2c34)O        1.857143   \n25                        c1cc2ccc3ccc(c4ccc(c1)c2c34)O        1.850000   \n26                        c1cc2ccc3ccc(c4ccc(c1)c2c34)O        1.851429   \n...                                                 ...             ...   \n2956  CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...        3.177143   \n2957  CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...        1.808571   \n2958  CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...        1.790000   \n2959  CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...        1.433333   \n2960  CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...        1.463333   \n\n      split_index  \n22              1  \n23              1  \n24              1  \n25              1  \n26              1  \n...           ...  \n2956            1  \n2957            2  \n2958            1  \n2959            1  \n2960            1  \n\n[836 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Organic_modifier</th>\n      <th>pH</th>\n      <th>Buffer</th>\n      <th>SMILES</th>\n      <th>retention_time</th>\n      <th>split_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>2.7</td>\n      <td>Formic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.822857</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>3.0</td>\n      <td>Acetic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>12.321429</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>3.0</td>\n      <td>Formic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.857143</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>5.0</td>\n      <td>Acetic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.850000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>5.0</td>\n      <td>Formic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.851429</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2956</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>5.0</td>\n      <td>Formic acid</td>\n      <td>CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...</td>\n      <td>3.177143</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2957</th>\n      <td>HILIC</td>\n      <td>Methanol</td>\n      <td>2.7</td>\n      <td>Formic acid</td>\n      <td>CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...</td>\n      <td>1.808571</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2958</th>\n      <td>HILIC</td>\n      <td>Methanol</td>\n      <td>3.0</td>\n      <td>Formic acid</td>\n      <td>CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...</td>\n      <td>1.790000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2959</th>\n      <td>HILIC</td>\n      <td>Methanol</td>\n      <td>5.0</td>\n      <td>Acetic acid</td>\n      <td>CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...</td>\n      <td>1.433333</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2960</th>\n      <td>HILIC</td>\n      <td>Methanol</td>\n      <td>5.0</td>\n      <td>Formic acid</td>\n      <td>CCCCC(=O)N(Cc1ccc(cc1)c1ccccc1c1n[nH]nn1)[C@@H...</td>\n      <td>1.463333</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>836 rows Ã— 7 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hilic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "data_hilic_with_descriptors = pd.concat([data_hilic, descriptors], axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "   Column Organic_modifier   pH       Buffer                         SMILES  \\\n22  HILIC     Acetonitrile  2.7  Formic acid  c1cc2ccc3ccc(c4ccc(c1)c2c34)O   \n23  HILIC     Acetonitrile  3.0  Acetic acid  c1cc2ccc3ccc(c4ccc(c1)c2c34)O   \n24  HILIC     Acetonitrile  3.0  Formic acid  c1cc2ccc3ccc(c4ccc(c1)c2c34)O   \n25  HILIC     Acetonitrile  5.0  Acetic acid  c1cc2ccc3ccc(c4ccc(c1)c2c34)O   \n26  HILIC     Acetonitrile  5.0  Formic acid  c1cc2ccc3ccc(c4ccc(c1)c2c34)O   \n\n    retention_time  split_index  \n22        1.822857            1  \n23       12.321429            1  \n24        1.857143            1  \n25        1.850000            1  \n26        1.851429            1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Column</th>\n      <th>Organic_modifier</th>\n      <th>pH</th>\n      <th>Buffer</th>\n      <th>SMILES</th>\n      <th>retention_time</th>\n      <th>split_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>2.7</td>\n      <td>Formic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.822857</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>3.0</td>\n      <td>Acetic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>12.321429</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>3.0</td>\n      <td>Formic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.857143</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>5.0</td>\n      <td>Acetic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.850000</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>HILIC</td>\n      <td>Acetonitrile</td>\n      <td>5.0</td>\n      <td>Formic acid</td>\n      <td>c1cc2ccc3ccc(c4ccc(c1)c2c34)O</td>\n      <td>1.851429</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hilic.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"models/multiRT/HILIC/\"\n",
      "AutoGluon Version:  0.4.1b20220404\n",
      "Python Version:     3.9.10\n",
      "Operating System:   Darwin\n",
      "Train Data Rows:    692\n",
      "Train Data Columns: 1617\n",
      "Label Column: retention_time\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (12.321428571428571, 1.0871428571428572, 2.64083, 1.70135)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I am compiled version of the rt prediction using autogluon and mordred descriptor calculator\n",
      "the usage is auto_rt_pred_with_autogluon(data, ignore_3d_label, savepath)\n",
      "the data is a dataframe with columns smiles, retention_time, and split split_index (1 training, 2 test)\n",
      "this function will returns a model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tAvailable Memory:                    4397.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 26.58 MB (0.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 299 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Column']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1325 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('object', []) :  291 | ['Organic_modifier', 'Buffer', 'AATS7dv', 'AATS8dv', 'AATS7d', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  183 | ['AATS7dv', 'AATS8dv', 'AATS7d', 'AATS8d', 'AATS7s', ...]\n",
      "\t\t('float', [])     : 1134 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('int', ['bool']) :  299 | ['Organic_modifier', 'Buffer', 'nBridgehead', 'nB', 'nBr', ...]\n",
      "\t1.6s = Fit runtime\n",
      "\t1616 features in original data used to generate 1616 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.71 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.69s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 553, Val Rows: 139\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.6963\t = Validation score   (root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.7659\t = Validation score   (root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-1.639\t = Validation score   (root_mean_squared_error)\n",
      "\t6.82s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-1.6536\t = Validation score   (root_mean_squared_error)\n",
      "\t3.39s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-1.6448\t = Validation score   (root_mean_squared_error)\n",
      "\t1.67s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\tWarning: Exception caused CatBoost to fail during training (ImportError)... Skipping this model.\n",
      "\t\t`import catboost` failed.A quick tip is to install via `pip install catboost`.\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-1.6454\t = Validation score   (root_mean_squared_error)\n",
      "\t0.88s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-1.6385\t = Validation score   (root_mean_squared_error)\n",
      "\t4.95s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-1.6509\t = Validation score   (root_mean_squared_error)\n",
      "\t3.66s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-1.7245\t = Validation score   (root_mean_squared_error)\n",
      "\t34.26s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-1.6563\t = Validation score   (root_mean_squared_error)\n",
      "\t7.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-1.6302\t = Validation score   (root_mean_squared_error)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 68.96s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"models/multiRT/HILIC/\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -1.630168       0.795998  11.948337                0.000576           0.084451            2       True         11\n",
      "1       NeuralNetFastAI  -1.638477       0.247779   4.948501                0.247779           4.948501            1       True          7\n",
      "2            LightGBMXT  -1.638981       0.024273   6.817855                0.024273           6.817855            1       True          3\n",
      "3       RandomForestMSE  -1.644790       0.032364   1.674599                0.032364           1.674599            1       True          5\n",
      "4         ExtraTreesMSE  -1.645437       0.032251   0.879601                0.032251           0.879601            1       True          6\n",
      "5               XGBoost  -1.650947       0.019909   3.658839                0.019909           3.658839            1       True          8\n",
      "6              LightGBM  -1.653594       0.023363   3.392452                0.023363           3.392452            1       True          4\n",
      "7         LightGBMLarge  -1.656340       0.023650   7.293026                0.023650           7.293026            1       True         10\n",
      "8        KNeighborsUnif  -1.696262       0.523370   0.097530                0.523370           0.097530            1       True          1\n",
      "9        NeuralNetTorch  -1.724471       0.127699  34.261856                0.127699          34.261856            1       True          9\n",
      "10       KNeighborsDist  -1.765931       0.803406   0.093645                0.803406           0.093645            1       True          2\n",
      "Number of models trained: 11\n",
      "Types of models trained:\n",
      "{'NNFastAiTabularModel', 'RFModel', 'KNNModel', 'TabularNeuralNetTorchModel', 'LGBModel', 'XGBoostModel', 'WeightedEnsembleModel', 'XTModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :  183 | ['AATS7dv', 'AATS8dv', 'AATS7d', 'AATS8d', 'AATS7s', ...]\n",
      "('float', [])     : 1134 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "('int', ['bool']) :  299 | ['Organic_modifier', 'Buffer', 'nBridgehead', 'nB', 'nBr', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'ExtraTreesMSE': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -1.6962620156642394, 'KNeighborsDist': -1.7659308855749276, 'LightGBMXT': -1.638981020326311, 'LightGBM': -1.653593602446336, 'RandomForestMSE': -1.6447904386248369, 'ExtraTreesMSE': -1.6454370452054798, 'NeuralNetFastAI': -1.6384766732125204, 'XGBoost': -1.650947342769947, 'NeuralNetTorch': -1.724471077995613, 'LightGBMLarge': -1.6563399788756932, 'WeightedEnsemble_L2': -1.6301684375577914}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': 'models/multiRT/HILIC/models/KNeighborsUnif/', 'KNeighborsDist': 'models/multiRT/HILIC/models/KNeighborsDist/', 'LightGBMXT': 'models/multiRT/HILIC/models/LightGBMXT/', 'LightGBM': 'models/multiRT/HILIC/models/LightGBM/', 'RandomForestMSE': 'models/multiRT/HILIC/models/RandomForestMSE/', 'ExtraTreesMSE': 'models/multiRT/HILIC/models/ExtraTreesMSE/', 'NeuralNetFastAI': 'models/multiRT/HILIC/models/NeuralNetFastAI/', 'XGBoost': 'models/multiRT/HILIC/models/XGBoost/', 'NeuralNetTorch': 'models/multiRT/HILIC/models/NeuralNetTorch/', 'LightGBMLarge': 'models/multiRT/HILIC/models/LightGBMLarge/', 'WeightedEnsemble_L2': 'models/multiRT/HILIC/models/WeightedEnsemble_L2/'}, 'model_fit_times': {'KNeighborsUnif': 0.09753012657165527, 'KNeighborsDist': 0.09364485740661621, 'LightGBMXT': 6.817854881286621, 'LightGBM': 3.3924520015716553, 'RandomForestMSE': 1.6745989322662354, 'ExtraTreesMSE': 0.879601001739502, 'NeuralNetFastAI': 4.948500871658325, 'XGBoost': 3.658838987350464, 'NeuralNetTorch': 34.26185584068298, 'LightGBMLarge': 7.293025970458984, 'WeightedEnsemble_L2': 0.08445072174072266}, 'model_pred_times': {'KNeighborsUnif': 0.5233700275421143, 'KNeighborsDist': 0.8034062385559082, 'LightGBMXT': 0.024273157119750977, 'LightGBM': 0.023363113403320312, 'RandomForestMSE': 0.0323638916015625, 'ExtraTreesMSE': 0.03225111961364746, 'NeuralNetFastAI': 0.24777913093566895, 'XGBoost': 0.019908905029296875, 'NeuralNetTorch': 0.1276991367340088, 'LightGBMLarge': 0.023650169372558594, 'WeightedEnsemble_L2': 0.000576019287109375}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'ExtraTreesMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val   fit_time  \\\n",
      "0   WeightedEnsemble_L2  -1.630168       0.795998  11.948337   \n",
      "1       NeuralNetFastAI  -1.638477       0.247779   4.948501   \n",
      "2            LightGBMXT  -1.638981       0.024273   6.817855   \n",
      "3       RandomForestMSE  -1.644790       0.032364   1.674599   \n",
      "4         ExtraTreesMSE  -1.645437       0.032251   0.879601   \n",
      "5               XGBoost  -1.650947       0.019909   3.658839   \n",
      "6              LightGBM  -1.653594       0.023363   3.392452   \n",
      "7         LightGBMLarge  -1.656340       0.023650   7.293026   \n",
      "8        KNeighborsUnif  -1.696262       0.523370   0.097530   \n",
      "9        NeuralNetTorch  -1.724471       0.127699  34.261856   \n",
      "10       KNeighborsDist  -1.765931       0.803406   0.093645   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000576           0.084451            2       True   \n",
      "1                 0.247779           4.948501            1       True   \n",
      "2                 0.024273           6.817855            1       True   \n",
      "3                 0.032364           1.674599            1       True   \n",
      "4                 0.032251           0.879601            1       True   \n",
      "5                 0.019909           3.658839            1       True   \n",
      "6                 0.023363           3.392452            1       True   \n",
      "7                 0.023650           7.293026            1       True   \n",
      "8                 0.523370           0.097530            1       True   \n",
      "9                 0.127699          34.261856            1       True   \n",
      "10                0.803406           0.093645            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          11  \n",
      "1           7  \n",
      "2           3  \n",
      "3           5  \n",
      "4           6  \n",
      "5           8  \n",
      "6           4  \n",
      "7          10  \n",
      "8           1  \n",
      "9           9  \n",
      "10          2  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -1.2101142802508555\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -1.2101142802508555,\n",
      "    \"mean_squared_error\": -1.4643765712670462,\n",
      "    \"mean_absolute_error\": -0.729227881976221,\n",
      "    \"r2\": 0.11030153251599939,\n",
      "    \"pearsonr\": 0.3547071707027939,\n",
      "    \"median_absolute_error\": -0.4656448277972993\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_mean_squared_error': -1.2101142802508555, 'mean_squared_error': -1.4643765712670462, 'mean_absolute_error': -0.729227881976221, 'r2': 0.11030153251599939, 'pearsonr': 0.3547071707027939, 'median_absolute_error': -0.4656448277972993}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x13f6c6f10>"
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_fit.auto_rt_pred_with_autogluon_with_descriptor(data_hilic_with_descriptors,\"models/multiRT/HILIC\" )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.9 (tensorflow)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}