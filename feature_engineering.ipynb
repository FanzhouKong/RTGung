{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d83617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi I am compiled version of the rt prediction using autogluon and mordred descriptor calculator\n",
      "the usage is make_descriptors(data) and auto_rt_pred_with_descriptor(data, savepath)\n",
      "the data is a dataframe with columns smiles, retention_time, and split_index (1 for training, 2 for test)\n",
      "this function will returns a model\n",
      "i am updated!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.ensemble\n",
    "import toolsets.auto_rt_pred as ap\n",
    "import toolsets.data_prep as data_prep\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import cleanlab\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate\n",
    "from cleanlab.filter import find_label_issues\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa919a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(\"data/multiRT/Combined dataset.csv\")\n",
    "hilic = combined_data.loc[combined_data['Column']=='HILIC']\n",
    "hilic.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "acfc25a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = pd.read_csv(\"data/multiRT/MultiRT_hilic_descriptors.csv\", engine='python')\n",
    "mixed_descriptors = descriptors.select_dtypes(exclude=['integer','floating','boolean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "79219293",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_descritptors = mixed_descriptors.apply(pd.to_numeric, errors='coerce',downcast='float')\n",
    "zero_descritptors.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4aa5c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors.update(zero_descritptors)\n",
    "descriptors = descriptors.select_dtypes(exclude=['boolean'])\n",
    "descriptors = descriptors.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "931a404e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 836 entries, 0 to 835\n",
      "Columns: 1611 entries, ABC to mZagreb2\n",
      "dtypes: float64(1611)\n",
      "memory usage: 10.3 MB\n"
     ]
    }
   ],
   "source": [
    "descriptors.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ab37f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([hilic, descriptors],axis =1)\n",
    "data = data_prep.dataset_prep(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb99cc28",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bc39fd6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the distinct rt intervals are ['(-inf, 3.44)' '[3.44, 4.58)' '[4.58, inf)']\n"
     ]
    }
   ],
   "source": [
    "data_bin = data_prep.bin_retention_time(data,'retention_time',variable = 'retention_time', bin_method = \"cart\", min_diff = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3041d1b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "data_confirmed, data_suspicious = data_prep.mislabeled_handling(data_bin, clf)\n",
    "data_confirmed = data_confirmed.drop(['retention_time_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692b9b8a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "75a67712",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"data/MultiRT/zero_version/hilic_data_raw.csv\", index = False)\n",
    "data_confirmed.to_csv(\"data/MultiRT/zero_version/hilic_data_confirmed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4896b5ca",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train, test = data_prep.make_train_test(data_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1edb383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"feature_engineered_models\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    638\n",
      "Train Data Columns: 1617\n",
      "Label Column: retention_time\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.588571428571427, 1.0871428571428572, 2.52215, 1.62956)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7538.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 8.45 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 66 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 292): ['Column', 'nBridgehead', 'nB', 'nBr', 'nI', 'SpAbs_Dt', 'SpMax_Dt', 'SpDiam_Dt', 'SpAD_Dt', 'SpMAD_Dt', 'LogEE_Dt', 'SM1_Dt', 'VE1_Dt', 'VE2_Dt', 'VE3_Dt', 'VR1_Dt', 'VR2_Dt', 'VR3_Dt', 'DetourIndex', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NssssN', 'NaaO', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SssssN', 'SaaO', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'MAXsLi', 'MAXssBe', 'MAXssssBe', 'MAXssBH', 'MAXsssB', 'MAXssssB', 'MAXddC', 'MAXsNH3', 'MAXssNH2', 'MAXsssNH', 'MAXssssN', 'MAXaaO', 'MAXsSiH3', 'MAXssSiH2', 'MAXsssSiH', 'MAXssssSi', 'MAXsPH2', 'MAXssPH', 'MAXsssP', 'MAXsssssP', 'MAXsGeH3', 'MAXssGeH2', 'MAXsssGeH', 'MAXssssGe', 'MAXsAsH2', 'MAXssAsH', 'MAXsssAs', 'MAXsssdAs', 'MAXsssssAs', 'MAXsSeH', 'MAXdSe', 'MAXssSe', 'MAXaaSe', 'MAXdssSe', 'MAXddssSe', 'MAXsBr', 'MAXsSnH3', 'MAXssSnH2', 'MAXsssSnH', 'MAXssssSn', 'MAXsI', 'MAXsPbH3', 'MAXssPbH2', 'MAXsssPbH', 'MAXssssPb', 'MINsLi', 'MINssBe', 'MINssssBe', 'MINssBH', 'MINsssB', 'MINssssB', 'MINddC', 'MINsNH3', 'MINssNH2', 'MINsssNH', 'MINssssN', 'MINaaO', 'MINsSiH3', 'MINssSiH2', 'MINsssSiH', 'MINssssSi', 'MINsPH2', 'MINssPH', 'MINsssP', 'MINsssssP', 'MINsGeH3', 'MINssGeH2', 'MINsssGeH', 'MINssssGe', 'MINsAsH2', 'MINssAsH', 'MINsssAs', 'MINsssdAs', 'MINsssssAs', 'MINsSeH', 'MINdSe', 'MINssSe', 'MINaaSe', 'MINdssSe', 'MINddssSe', 'MINsBr', 'MINsSnH3', 'MINssSnH2', 'MINsssSnH', 'MINssssSn', 'MINsI', 'MINsPbH3', 'MINssPbH2', 'MINsssPbH', 'MINssssPb', 'ETA_dPsi_B', 'SMR_VSA8', 'SlogP_VSA9', 'n4Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n4ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n11FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n11FHRing', 'n12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n11FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n11FAHRing', 'n12FAHRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1321 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('object', []) :    4 | ['Compound_name', 'Organic_modifier', 'Buffer', 'SMILES']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "\t\t('float', [])     : 1257 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('int', ['bool']) :   66 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "\t1.3s = Fit runtime\n",
      "\t1325 features in original data used to generate 1325 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 6.46 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.41s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 510, Val Rows: 128\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.1299\t = Validation score   (root_mean_squared_error)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.1816\t = Validation score   (root_mean_squared_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.500132\n",
      "[2000]\tvalid_set's rmse: 0.484688\n",
      "[3000]\tvalid_set's rmse: 0.483235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4832\t = Validation score   (root_mean_squared_error)\n",
      "\t8.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.544362\n",
      "[2000]\tvalid_set's rmse: 0.525755\n",
      "[3000]\tvalid_set's rmse: 0.5194\n",
      "[4000]\tvalid_set's rmse: 0.51674\n",
      "[5000]\tvalid_set's rmse: 0.515693\n",
      "[6000]\tvalid_set's rmse: 0.515261\n",
      "[7000]\tvalid_set's rmse: 0.514844\n",
      "[8000]\tvalid_set's rmse: 0.514633\n",
      "[9000]\tvalid_set's rmse: 0.514578\n",
      "[10000]\tvalid_set's rmse: 0.51455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5145\t = Validation score   (root_mean_squared_error)\n",
      "\t36.18s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.5666\t = Validation score   (root_mean_squared_error)\n",
      "\t5.29s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.6445\t = Validation score   (root_mean_squared_error)\n",
      "\t484.23s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.6479\t = Validation score   (root_mean_squared_error)\n",
      "\t1.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-1.1029\t = Validation score   (root_mean_squared_error)\n",
      "\t4.84s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.3854\t = Validation score   (root_mean_squared_error)\n",
      "\t12.67s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-1.1365\t = Validation score   (root_mean_squared_error)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.569217\n",
      "[2000]\tvalid_set's rmse: 0.562235\n",
      "[3000]\tvalid_set's rmse: 0.559521\n",
      "[4000]\tvalid_set's rmse: 0.559025\n",
      "[5000]\tvalid_set's rmse: 0.558742\n",
      "[6000]\tvalid_set's rmse: 0.558621\n",
      "[7000]\tvalid_set's rmse: 0.558601\n",
      "[8000]\tvalid_set's rmse: 0.558582\n",
      "[9000]\tvalid_set's rmse: 0.558568\n",
      "[10000]\tvalid_set's rmse: 0.558548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5585\t = Validation score   (root_mean_squared_error)\n",
      "\t144.66s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.3821\t = Validation score   (root_mean_squared_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 707.73s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"feature_engineered_models\\\")\n",
      "Evaluation: root_mean_squared_error on test data: -0.38589621066394897\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.38589621066394897,\n",
      "    \"mean_squared_error\": -0.14891588540479483,\n",
      "    \"mean_absolute_error\": -0.16756896815837471,\n",
      "    \"r2\": 0.8818307575142841,\n",
      "    \"pearsonr\": 0.9432148249089679,\n",
      "    \"median_absolute_error\": -0.03943631989615304\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -0.382139       0.034008   20.870521                0.000000           0.194044            2       True         12\n",
      "1               XGBoost  -0.385432       0.016003   12.668661                0.016003          12.668661            1       True          9\n",
      "2            LightGBMXT  -0.483200       0.018005    8.007816                0.018005           8.007816            1       True          3\n",
      "3              LightGBM  -0.514549       0.051011   36.176503                0.051011          36.176503            1       True          4\n",
      "4         LightGBMLarge  -0.558548       0.052011  144.658660                0.052011         144.658660            1       True         11\n",
      "5       RandomForestMSE  -0.566554       0.037009    5.285693                0.037009           5.285693            1       True          5\n",
      "6              CatBoost  -0.644521       0.047012  484.234700                0.047012         484.234700            1       True          6\n",
      "7         ExtraTreesMSE  -0.647871       0.035009    1.597393                0.035009           1.597393            1       True          7\n",
      "8       NeuralNetFastAI  -1.102888       0.545129    4.838406                0.545129           4.838406            1       True          8\n",
      "9        KNeighborsUnif  -1.129903       0.030006    0.123027                0.030006           0.123027            1       True          1\n",
      "10       NeuralNetTorch  -1.136460       0.309069    3.582308                0.309069           3.582308            1       True         10\n",
      "11       KNeighborsDist  -1.181578       0.028005    0.189043                0.028005           0.189043            1       True          2\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'RFModel', 'TabularNeuralNetTorchModel', 'XTModel', 'LGBModel', 'KNNModel', 'NNFastAiTabularModel', 'XGBoostModel', 'CatBoostModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "('float', [])     : 1257 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "('int', ['bool']) :   66 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'CatBoost': 'CatBoostModel', 'ExtraTreesMSE': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -1.129903036119442, 'KNeighborsDist': -1.1815784692109412, 'LightGBMXT': -0.4831998205202382, 'LightGBM': -0.5145494670011748, 'RandomForestMSE': -0.5665539801286801, 'CatBoost': -0.6445210038126443, 'ExtraTreesMSE': -0.6478713149891253, 'NeuralNetFastAI': -1.1028882232664823, 'XGBoost': -0.38543156148523255, 'NeuralNetTorch': -1.1364598919502962, 'LightGBMLarge': -0.5585475681721844, 'WeightedEnsemble_L2': -0.3821392085630762}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': 'feature_engineered_models\\\\models\\\\KNeighborsUnif\\\\', 'KNeighborsDist': 'feature_engineered_models\\\\models\\\\KNeighborsDist\\\\', 'LightGBMXT': 'feature_engineered_models\\\\models\\\\LightGBMXT\\\\', 'LightGBM': 'feature_engineered_models\\\\models\\\\LightGBM\\\\', 'RandomForestMSE': 'feature_engineered_models\\\\models\\\\RandomForestMSE\\\\', 'CatBoost': 'feature_engineered_models\\\\models\\\\CatBoost\\\\', 'ExtraTreesMSE': 'feature_engineered_models\\\\models\\\\ExtraTreesMSE\\\\', 'NeuralNetFastAI': 'feature_engineered_models\\\\models\\\\NeuralNetFastAI\\\\', 'XGBoost': 'feature_engineered_models\\\\models\\\\XGBoost\\\\', 'NeuralNetTorch': 'feature_engineered_models\\\\models\\\\NeuralNetTorch\\\\', 'LightGBMLarge': 'feature_engineered_models\\\\models\\\\LightGBMLarge\\\\', 'WeightedEnsemble_L2': 'feature_engineered_models\\\\models\\\\WeightedEnsemble_L2\\\\'}, 'model_fit_times': {'KNeighborsUnif': 0.12302660942077637, 'KNeighborsDist': 0.18904328346252441, 'LightGBMXT': 8.007815599441528, 'LightGBM': 36.17650270462036, 'RandomForestMSE': 5.285692930221558, 'CatBoost': 484.23469972610474, 'ExtraTreesMSE': 1.5973927974700928, 'NeuralNetFastAI': 4.838406085968018, 'XGBoost': 12.668661117553711, 'NeuralNetTorch': 3.582308292388916, 'LightGBMLarge': 144.65866041183472, 'WeightedEnsemble_L2': 0.1940441131591797}, 'model_pred_times': {'KNeighborsUnif': 0.030005693435668945, 'KNeighborsDist': 0.028005361557006836, 'LightGBMXT': 0.018004655838012695, 'LightGBM': 0.0510106086730957, 'RandomForestMSE': 0.03700876235961914, 'CatBoost': 0.0470120906829834, 'ExtraTreesMSE': 0.03500938415527344, 'NeuralNetFastAI': 0.545128583908081, 'XGBoost': 0.016003131866455078, 'NeuralNetTorch': 0.3090691566467285, 'LightGBMLarge': 0.05201101303100586, 'WeightedEnsemble_L2': 0.0}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'CatBoost': {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}, 'ExtraTreesMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val    fit_time  \\\n",
      "0   WeightedEnsemble_L2  -0.382139       0.034008   20.870521   \n",
      "1               XGBoost  -0.385432       0.016003   12.668661   \n",
      "2            LightGBMXT  -0.483200       0.018005    8.007816   \n",
      "3              LightGBM  -0.514549       0.051011   36.176503   \n",
      "4         LightGBMLarge  -0.558548       0.052011  144.658660   \n",
      "5       RandomForestMSE  -0.566554       0.037009    5.285693   \n",
      "6              CatBoost  -0.644521       0.047012  484.234700   \n",
      "7         ExtraTreesMSE  -0.647871       0.035009    1.597393   \n",
      "8       NeuralNetFastAI  -1.102888       0.545129    4.838406   \n",
      "9        KNeighborsUnif  -1.129903       0.030006    0.123027   \n",
      "10       NeuralNetTorch  -1.136460       0.309069    3.582308   \n",
      "11       KNeighborsDist  -1.181578       0.028005    0.189043   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000000           0.194044            2       True   \n",
      "1                 0.016003          12.668661            1       True   \n",
      "2                 0.018005           8.007816            1       True   \n",
      "3                 0.051011          36.176503            1       True   \n",
      "4                 0.052011         144.658660            1       True   \n",
      "5                 0.037009           5.285693            1       True   \n",
      "6                 0.047012         484.234700            1       True   \n",
      "7                 0.035009           1.597393            1       True   \n",
      "8                 0.545129           4.838406            1       True   \n",
      "9                 0.030006           0.123027            1       True   \n",
      "10                0.309069           3.582308            1       True   \n",
      "11                0.028005           0.189043            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          12  \n",
      "1           9  \n",
      "2           3  \n",
      "3           4  \n",
      "4          11  \n",
      "5           5  \n",
      "6           6  \n",
      "7           7  \n",
      "8           8  \n",
      "9           1  \n",
      "10         10  \n",
      "11          2  }\n",
      "{'root_mean_squared_error': -0.38589621066394897, 'mean_squared_error': -0.14891588540479483, 'mean_absolute_error': -0.16756896815837471, 'r2': 0.8818307575142841, 'pearsonr': 0.9432148249089679, 'median_absolute_error': -0.03943631989615304}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x1403b887610>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.autogluon_fit_train_test (train, test, 'feature_engineered_models') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638d564",
   "metadata": {},
   "source": [
    "# mean descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3daa2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = pd.read_csv(\"data/multiRT/MultiRT_hilic_descriptors.csv\", engine='python')\n",
    "mixed_descriptors = descriptors.select_dtypes(exclude=['integer','floating','boolean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f309213e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AATS7dv</th>\n",
       "      <th>AATS8dv</th>\n",
       "      <th>AATS7d</th>\n",
       "      <th>AATS8d</th>\n",
       "      <th>AATS7s</th>\n",
       "      <th>AATS8s</th>\n",
       "      <th>AATS7Z</th>\n",
       "      <th>AATS8Z</th>\n",
       "      <th>AATS7m</th>\n",
       "      <th>AATS8m</th>\n",
       "      <th>...</th>\n",
       "      <th>MDEC-44</th>\n",
       "      <th>MDEO-11</th>\n",
       "      <th>MDEO-12</th>\n",
       "      <th>MDEO-22</th>\n",
       "      <th>MDEN-11</th>\n",
       "      <th>MDEN-12</th>\n",
       "      <th>MDEN-13</th>\n",
       "      <th>MDEN-22</th>\n",
       "      <th>MDEN-23</th>\n",
       "      <th>MDEN-33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows  287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AATS7dv   AATS8dv    AATS7d    AATS8d    AATS7s    AATS8s     AATS7Z  \\\n",
       "0    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "1    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "2    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "3    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "4    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "831  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "832  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "833  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "834  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "835  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "\n",
       "        AATS8Z     AATS7m     AATS8m  ...  MDEC-44   MDEO-11  MDEO-12  \\\n",
       "0     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "1     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "2     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "3     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "4     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "..         ...        ...        ...  ...      ...       ...      ...   \n",
       "831  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "832  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "833  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "834  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "835  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "\n",
       "     MDEO-22  MDEN-11  MDEN-12  MDEN-13  MDEN-22   MDEN-23  MDEN-33  \n",
       "0        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "1        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "2        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "3        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "4        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "..       ...      ...      ...      ...      ...       ...      ...  \n",
       "831      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "832      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "833      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "834      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "835      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "\n",
       "[836 rows x 287 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_descritptors = mixed_descriptors.apply(pd.to_numeric, errors='coerce',downcast='float')\n",
    "# mean_descritptors.fillna(0,inplace=True)\n",
    "# mean_descritptors = mean_descritptors.astype('float64')\n",
    "mean_descritptors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95c5b620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AATS7dv</th>\n",
       "      <th>AATS8dv</th>\n",
       "      <th>AATS7d</th>\n",
       "      <th>AATS8d</th>\n",
       "      <th>AATS7s</th>\n",
       "      <th>AATS8s</th>\n",
       "      <th>AATS7Z</th>\n",
       "      <th>AATS8Z</th>\n",
       "      <th>AATS7m</th>\n",
       "      <th>AATS8m</th>\n",
       "      <th>...</th>\n",
       "      <th>MDEC-44</th>\n",
       "      <th>MDEO-11</th>\n",
       "      <th>MDEO-12</th>\n",
       "      <th>MDEO-22</th>\n",
       "      <th>MDEN-11</th>\n",
       "      <th>MDEN-12</th>\n",
       "      <th>MDEN-13</th>\n",
       "      <th>MDEN-22</th>\n",
       "      <th>MDEN-23</th>\n",
       "      <th>MDEN-33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.650894</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>2.234607</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.650894</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>2.234607</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.650894</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>2.234607</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.650894</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>2.234607</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.650894</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>2.234607</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.935013</td>\n",
       "      <td>1.218126</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.811509</td>\n",
       "      <td>0.479806</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.670192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows  287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AATS7dv   AATS8dv    AATS7d    AATS8d    AATS7s    AATS8s     AATS7Z  \\\n",
       "0    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "1    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "2    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "3    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "4    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "831  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "832  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "833  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "834  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "835  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "\n",
       "        AATS8Z     AATS7m     AATS8m  ...   MDEC-44   MDEO-11   MDEO-12  \\\n",
       "0     3.200000  22.348194   5.854464  ...  0.513875  0.650894  0.935013   \n",
       "1     3.200000  22.348194   5.854464  ...  0.513875  0.650894  0.935013   \n",
       "2     3.200000  22.348194   5.854464  ...  0.513875  0.650894  0.935013   \n",
       "3     3.200000  22.348194   5.854464  ...  0.513875  0.650894  0.935013   \n",
       "4     3.200000  22.348194   5.854464  ...  0.513875  0.650894  0.935013   \n",
       "..         ...        ...        ...  ...       ...       ...       ...   \n",
       "831  10.347561  41.331139  34.430214  ...  0.513875  0.814325  0.935013   \n",
       "832  10.347561  41.331139  34.430214  ...  0.513875  0.814325  0.935013   \n",
       "833  10.347561  41.331139  34.430214  ...  0.513875  0.814325  0.935013   \n",
       "834  10.347561  41.331139  34.430214  ...  0.513875  0.814325  0.935013   \n",
       "835  10.347561  41.331139  34.430214  ...  0.513875  0.814325  0.935013   \n",
       "\n",
       "      MDEO-22   MDEN-11   MDEN-12   MDEN-13   MDEN-22   MDEN-23   MDEN-33  \n",
       "0    1.218126  0.411765  0.811509  0.479806  2.234607  0.824821  0.670192  \n",
       "1    1.218126  0.411765  0.811509  0.479806  2.234607  0.824821  0.670192  \n",
       "2    1.218126  0.411765  0.811509  0.479806  2.234607  0.824821  0.670192  \n",
       "3    1.218126  0.411765  0.811509  0.479806  2.234607  0.824821  0.670192  \n",
       "4    1.218126  0.411765  0.811509  0.479806  2.234607  0.824821  0.670192  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "831  1.218126  0.411765  0.811509  0.479806  4.242640  0.421637  0.670192  \n",
       "832  1.218126  0.411765  0.811509  0.479806  4.242640  0.421637  0.670192  \n",
       "833  1.218126  0.411765  0.811509  0.479806  4.242640  0.421637  0.670192  \n",
       "834  1.218126  0.411765  0.811509  0.479806  4.242640  0.421637  0.670192  \n",
       "835  1.218126  0.411765  0.811509  0.479806  4.242640  0.421637  0.670192  \n",
       "\n",
       "[836 rows x 287 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in mean_descritptors.columns[0:]:\n",
    "    col_mean = mean_descritptors[col].mean()\n",
    "    mean_descritptors[col] = mean_descritptors[col].replace(np.nan, col_mean)\n",
    "mean_descritptors.to_csv('mean_descritptors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9728c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors.update(mean_descritptors)\n",
    "descriptors = descriptors.select_dtypes(exclude=['boolean','object'])\n",
    "descriptors = descriptors.astype('float64')\n",
    "data = pd.concat([hilic, descriptors],axis =1)\n",
    "data = data_prep.dataset_prep(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6053c4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the distinct rt intervals are ['(-inf, 3.44)' '[3.44, 4.58)' '[4.58, inf)']\n"
     ]
    }
   ],
   "source": [
    "data_bin = data_prep.bin_retention_time(data,'retention_time',variable = 'retention_time', bin_method = \"cart\", min_diff = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee838351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have passed cv!\n",
      "Cleanlab found 42 potential label errors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "data_confirmed, data_suspicious = data_prep.mislabeled_handling(data_bin, clf)\n",
    "data_confirmed = data_confirmed.drop(['retention_time_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6bc9e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/MultiRT/mean_version/hilic_data_raw.csv\", index = False)\n",
    "data_confirmed.to_csv(\"data/MultiRT/mean_version/hilic_data_confirmed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ac2faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_prep.make_train_test(data_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45b25d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"feature_engineered_models_mean\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"feature_engineered_models_mean\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    636\n",
      "Train Data Columns: 1330\n",
      "Label Column: retention_time\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.588571428571427, 1.0871428571428572, 2.51549, 1.61379)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6062.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.97 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 56 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 188): ['Column', 'nBridgehead', 'nB', 'nBr', 'nI', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NssssN', 'NaaO', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SssssN', 'SaaO', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'ETA_dPsi_B', 'SMR_VSA8', 'SlogP_VSA9', 'n4Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n4ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n11FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n11FHRing', 'n12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n11FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n11FAHRing', 'n12FAHRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1138 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('object', []) :    4 | ['Compound_name', 'Organic_modifier', 'Buffer', 'SMILES']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "\t\t('float', [])     : 1084 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('int', ['bool']) :   56 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "\t0.9s = Fit runtime\n",
      "\t1142 features in original data used to generate 1142 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.55 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.01s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 508, Val Rows: 128\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.0228\t = Validation score   (root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.0657\t = Validation score   (root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.466792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4655\t = Validation score   (root_mean_squared_error)\n",
      "\t2.28s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t-0.4941\t = Validation score   (root_mean_squared_error)\n",
      "\t3.58s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.496498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.5167\t = Validation score   (root_mean_squared_error)\n",
      "\t3.51s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.4389\t = Validation score   (root_mean_squared_error)\n",
      "\t189.38s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.494\t = Validation score   (root_mean_squared_error)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-1.08\t = Validation score   (root_mean_squared_error)\n",
      "\t2.91s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.4036\t = Validation score   (root_mean_squared_error)\n",
      "\t13.04s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-1.0667\t = Validation score   (root_mean_squared_error)\n",
      "\t3.27s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.4545\t = Validation score   (root_mean_squared_error)\n",
      "\t10.93s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.3649\t = Validation score   (root_mean_squared_error)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 234.23s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"feature_engineered_models_mean\\\")\n",
      "Evaluation: root_mean_squared_error on test data: -0.37783383397848974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -0.364851       0.092021  208.498204                0.000000           0.215049            2       True         12\n",
      "1               XGBoost  -0.403602       0.024005   13.044140                0.024005          13.044140            1       True          9\n",
      "2              CatBoost  -0.438900       0.039009  189.382289                0.039009         189.382289            1       True          6\n",
      "3         LightGBMLarge  -0.454476       0.017004   10.925461                0.017004          10.925461            1       True         11\n",
      "4            LightGBMXT  -0.465486       0.015003    2.276917                0.015003           2.276917            1       True          3\n",
      "5         ExtraTreesMSE  -0.493973       0.038008    1.412406                0.038008           1.412406            1       True          7\n",
      "6              LightGBM  -0.494141       0.014003    3.579809                0.014003           3.579809            1       True          4\n",
      "7       RandomForestMSE  -0.516698       0.034007    3.506793                0.034007           3.506793            1       True          5\n",
      "8        KNeighborsUnif  -1.022823       0.020421    0.100023                0.020421           0.100023            1       True          1\n",
      "9        KNeighborsDist  -1.065661       0.025006    0.159036                0.025006           0.159036            1       True          2\n",
      "10       NeuralNetTorch  -1.066671       0.291916    3.267738                0.291916           3.267738            1       True         10\n",
      "11      NeuralNetFastAI  -1.080019       0.450102    2.907472                0.450102           2.907472            1       True          8\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'LGBModel', 'XTModel', 'RFModel', 'KNNModel', 'TabularNeuralNetTorchModel', 'XGBoostModel', 'CatBoostModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "('float', [])     : 1084 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "('int', ['bool']) :   56 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'CatBoost': 'CatBoostModel', 'ExtraTreesMSE': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -1.0228225045403543, 'KNeighborsDist': -1.0656609170302822, 'LightGBMXT': -0.46548590186674305, 'LightGBM': -0.4941410538314607, 'RandomForestMSE': -0.5166981763893562, 'CatBoost': -0.4389002174560134, 'ExtraTreesMSE': -0.4939734783408077, 'NeuralNetFastAI': -1.0800191755347144, 'XGBoost': -0.40360202855937233, 'NeuralNetTorch': -1.066670523939329, 'LightGBMLarge': -0.4544759720412952, 'WeightedEnsemble_L2': -0.36485124511114364}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': 'feature_engineered_models_mean\\\\models\\\\KNeighborsUnif\\\\', 'KNeighborsDist': 'feature_engineered_models_mean\\\\models\\\\KNeighborsDist\\\\', 'LightGBMXT': 'feature_engineered_models_mean\\\\models\\\\LightGBMXT\\\\', 'LightGBM': 'feature_engineered_models_mean\\\\models\\\\LightGBM\\\\', 'RandomForestMSE': 'feature_engineered_models_mean\\\\models\\\\RandomForestMSE\\\\', 'CatBoost': 'feature_engineered_models_mean\\\\models\\\\CatBoost\\\\', 'ExtraTreesMSE': 'feature_engineered_models_mean\\\\models\\\\ExtraTreesMSE\\\\', 'NeuralNetFastAI': 'feature_engineered_models_mean\\\\models\\\\NeuralNetFastAI\\\\', 'XGBoost': 'feature_engineered_models_mean\\\\models\\\\XGBoost\\\\', 'NeuralNetTorch': 'feature_engineered_models_mean\\\\models\\\\NeuralNetTorch\\\\', 'LightGBMLarge': 'feature_engineered_models_mean\\\\models\\\\LightGBMLarge\\\\', 'WeightedEnsemble_L2': 'feature_engineered_models_mean\\\\models\\\\WeightedEnsemble_L2\\\\'}, 'model_fit_times': {'KNeighborsUnif': 0.10002255439758301, 'KNeighborsDist': 0.15903615951538086, 'LightGBMXT': 2.2769172191619873, 'LightGBM': 3.5798087120056152, 'RandomForestMSE': 3.50679349899292, 'CatBoost': 189.38228940963745, 'ExtraTreesMSE': 1.4124057292938232, 'NeuralNetFastAI': 2.9074721336364746, 'XGBoost': 13.044139623641968, 'NeuralNetTorch': 3.267737627029419, 'LightGBMLarge': 10.925461053848267, 'WeightedEnsemble_L2': 0.21504878997802734}, 'model_pred_times': {'KNeighborsUnif': 0.02042102813720703, 'KNeighborsDist': 0.025005578994750977, 'LightGBMXT': 0.015003442764282227, 'LightGBM': 0.01400303840637207, 'RandomForestMSE': 0.03400731086730957, 'CatBoost': 0.03900885581970215, 'ExtraTreesMSE': 0.03800797462463379, 'NeuralNetFastAI': 0.4501018524169922, 'XGBoost': 0.02400517463684082, 'NeuralNetTorch': 0.2919156551361084, 'LightGBMLarge': 0.01700425148010254, 'WeightedEnsemble_L2': 0.0}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'CatBoost': {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}, 'ExtraTreesMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val    fit_time  \\\n",
      "0   WeightedEnsemble_L2  -0.364851       0.092021  208.498204   \n",
      "1               XGBoost  -0.403602       0.024005   13.044140   \n",
      "2              CatBoost  -0.438900       0.039009  189.382289   \n",
      "3         LightGBMLarge  -0.454476       0.017004   10.925461   \n",
      "4            LightGBMXT  -0.465486       0.015003    2.276917   \n",
      "5         ExtraTreesMSE  -0.493973       0.038008    1.412406   \n",
      "6              LightGBM  -0.494141       0.014003    3.579809   \n",
      "7       RandomForestMSE  -0.516698       0.034007    3.506793   \n",
      "8        KNeighborsUnif  -1.022823       0.020421    0.100023   \n",
      "9        KNeighborsDist  -1.065661       0.025006    0.159036   \n",
      "10       NeuralNetTorch  -1.066671       0.291916    3.267738   \n",
      "11      NeuralNetFastAI  -1.080019       0.450102    2.907472   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000000           0.215049            2       True   \n",
      "1                 0.024005          13.044140            1       True   \n",
      "2                 0.039009         189.382289            1       True   \n",
      "3                 0.017004          10.925461            1       True   \n",
      "4                 0.015003           2.276917            1       True   \n",
      "5                 0.038008           1.412406            1       True   \n",
      "6                 0.014003           3.579809            1       True   \n",
      "7                 0.034007           3.506793            1       True   \n",
      "8                 0.020421           0.100023            1       True   \n",
      "9                 0.025006           0.159036            1       True   \n",
      "10                0.291916           3.267738            1       True   \n",
      "11                0.450102           2.907472            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          12  \n",
      "1           9  \n",
      "2           6  \n",
      "3          11  \n",
      "4           3  \n",
      "5           7  \n",
      "6           4  \n",
      "7           5  \n",
      "8           1  \n",
      "9           2  \n",
      "10         10  \n",
      "11          8  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.37783383397848974,\n",
      "    \"mean_squared_error\": -0.14275840609888504,\n",
      "    \"mean_absolute_error\": -0.170224461671313,\n",
      "    \"r2\": 0.896309147557784,\n",
      "    \"pearsonr\": 0.9469719861031289,\n",
      "    \"median_absolute_error\": -0.042083891119275796\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_mean_squared_error': -0.37783383397848974, 'mean_squared_error': -0.14275840609888504, 'mean_absolute_error': -0.170224461671313, 'r2': 0.896309147557784, 'pearsonr': 0.9469719861031289, 'median_absolute_error': -0.042083891119275796}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x2f92b1bc520>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.autogluon_fit_train_test (train, test, 'feature_engineered_models_mean') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a38b303",
   "metadata": {},
   "source": [
    "# median descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c13fb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = pd.read_csv(\"data/multiRT/MultiRT_hilic_descriptors.csv\", engine='python')\n",
    "mixed_descriptors = descriptors.select_dtypes(exclude=['integer','floating','boolean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "314d1434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AATS7dv</th>\n",
       "      <th>AATS8dv</th>\n",
       "      <th>AATS7d</th>\n",
       "      <th>AATS8d</th>\n",
       "      <th>AATS7s</th>\n",
       "      <th>AATS8s</th>\n",
       "      <th>AATS7Z</th>\n",
       "      <th>AATS8Z</th>\n",
       "      <th>AATS7m</th>\n",
       "      <th>AATS8m</th>\n",
       "      <th>...</th>\n",
       "      <th>MDEC-44</th>\n",
       "      <th>MDEO-11</th>\n",
       "      <th>MDEO-12</th>\n",
       "      <th>MDEO-22</th>\n",
       "      <th>MDEN-11</th>\n",
       "      <th>MDEN-12</th>\n",
       "      <th>MDEN-13</th>\n",
       "      <th>MDEN-22</th>\n",
       "      <th>MDEN-23</th>\n",
       "      <th>MDEN-33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows  287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AATS7dv   AATS8dv    AATS7d    AATS8d    AATS7s    AATS8s     AATS7Z  \\\n",
       "0    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "1    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "2    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "3    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "4    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "831  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "832  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "833  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "834  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "835  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "\n",
       "        AATS8Z     AATS7m     AATS8m  ...  MDEC-44   MDEO-11  MDEO-12  \\\n",
       "0     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "1     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "2     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "3     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "4     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "..         ...        ...        ...  ...      ...       ...      ...   \n",
       "831  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "832  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "833  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "834  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "835  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "\n",
       "     MDEO-22  MDEN-11  MDEN-12  MDEN-13  MDEN-22   MDEN-23  MDEN-33  \n",
       "0        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "1        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "2        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "3        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "4        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "..       ...      ...      ...      ...      ...       ...      ...  \n",
       "831      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "832      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "833      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "834      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "835      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "\n",
       "[836 rows x 287 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median_descritptors = mixed_descriptors.apply(pd.to_numeric, errors='coerce',downcast='float')\n",
    "median_descritptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c730429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AATS7dv</th>\n",
       "      <th>AATS8dv</th>\n",
       "      <th>AATS7d</th>\n",
       "      <th>AATS8d</th>\n",
       "      <th>AATS7s</th>\n",
       "      <th>AATS8s</th>\n",
       "      <th>AATS7Z</th>\n",
       "      <th>AATS8Z</th>\n",
       "      <th>AATS7m</th>\n",
       "      <th>AATS8m</th>\n",
       "      <th>...</th>\n",
       "      <th>MDEC-44</th>\n",
       "      <th>MDEO-11</th>\n",
       "      <th>MDEO-12</th>\n",
       "      <th>MDEO-22</th>\n",
       "      <th>MDEN-11</th>\n",
       "      <th>MDEN-12</th>\n",
       "      <th>MDEN-13</th>\n",
       "      <th>MDEN-22</th>\n",
       "      <th>MDEN-23</th>\n",
       "      <th>MDEN-33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.381102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.381102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.381102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.381102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.381102</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>0.825482</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.412741</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.242640</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows  287 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AATS7dv   AATS8dv    AATS7d    AATS8d    AATS7s    AATS8s     AATS7Z  \\\n",
       "0    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "1    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "2    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "3    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "4    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "831  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "832  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "833  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "834  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "835  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "\n",
       "        AATS8Z     AATS7m     AATS8m  ...  MDEC-44   MDEO-11   MDEO-12  \\\n",
       "0     3.200000  22.348194   5.854464  ...     0.25  0.500000  0.825482   \n",
       "1     3.200000  22.348194   5.854464  ...     0.25  0.500000  0.825482   \n",
       "2     3.200000  22.348194   5.854464  ...     0.25  0.500000  0.825482   \n",
       "3     3.200000  22.348194   5.854464  ...     0.25  0.500000  0.825482   \n",
       "4     3.200000  22.348194   5.854464  ...     0.25  0.500000  0.825482   \n",
       "..         ...        ...        ...  ...      ...       ...       ...   \n",
       "831  10.347561  41.331139  34.430214  ...     0.25  0.814325  0.825482   \n",
       "832  10.347561  41.331139  34.430214  ...     0.25  0.814325  0.825482   \n",
       "833  10.347561  41.331139  34.430214  ...     0.25  0.814325  0.825482   \n",
       "834  10.347561  41.331139  34.430214  ...     0.25  0.814325  0.825482   \n",
       "835  10.347561  41.331139  34.430214  ...     0.25  0.814325  0.825482   \n",
       "\n",
       "     MDEO-22  MDEN-11   MDEN-12  MDEN-13   MDEN-22   MDEN-23  MDEN-33  \n",
       "0        1.5     0.25  0.412741      0.5  2.381102  0.500000      0.5  \n",
       "1        1.5     0.25  0.412741      0.5  2.381102  0.500000      0.5  \n",
       "2        1.5     0.25  0.412741      0.5  2.381102  0.500000      0.5  \n",
       "3        1.5     0.25  0.412741      0.5  2.381102  0.500000      0.5  \n",
       "4        1.5     0.25  0.412741      0.5  2.381102  0.500000      0.5  \n",
       "..       ...      ...       ...      ...       ...       ...      ...  \n",
       "831      1.5     0.25  0.412741      0.5  4.242640  0.421637      0.5  \n",
       "832      1.5     0.25  0.412741      0.5  4.242640  0.421637      0.5  \n",
       "833      1.5     0.25  0.412741      0.5  4.242640  0.421637      0.5  \n",
       "834      1.5     0.25  0.412741      0.5  4.242640  0.421637      0.5  \n",
       "835      1.5     0.25  0.412741      0.5  4.242640  0.421637      0.5  \n",
       "\n",
       "[836 rows x 287 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in median_descritptors.columns[0:]:\n",
    "    col_median = median_descritptors[col].median()\n",
    "    median_descritptors[col] = median_descritptors[col].replace(np.nan, col_median)\n",
    "median_descritptors.to_csv('median_descritptors.csv')\n",
    "median_descritptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8cf4b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors.update(median_descritptors)\n",
    "descriptors = descriptors.select_dtypes(exclude=['boolean','object'])\n",
    "descriptors = descriptors.astype('float64')\n",
    "data = pd.concat([hilic, descriptors],axis =1)\n",
    "data = data_prep.dataset_prep(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0b7abee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have passed cv!\n",
      "Cleanlab found 41 potential label errors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "data_confirmed, data_suspicious = data_prep.mislabeled_handling(data_bin, clf)\n",
    "data_confirmed = data_confirmed.drop(['retention_time_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbb2955e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/MultiRT/median_version/hilic_data_raw.csv\", index = False)\n",
    "data_confirmed.to_csv(\"data/MultiRT/median_version/hilic_data_confirmed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8b65130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_prep.make_train_test(data_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b80576e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"feature_engineered_models_median\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"feature_engineered_models_median\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    637\n",
      "Train Data Columns: 1330\n",
      "Label Column: retention_time\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.588571428571427, 1.0871428571428572, 2.52383, 1.63494)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6041.31 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.98 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 56 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 188): ['Column', 'nBridgehead', 'nB', 'nBr', 'nI', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NssssN', 'NaaO', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SssssN', 'SaaO', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'ETA_dPsi_B', 'SMR_VSA8', 'SlogP_VSA9', 'n4Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n4ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n11FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n11FHRing', 'n12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n11FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n11FAHRing', 'n12FAHRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1138 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('object', []) :    4 | ['Compound_name', 'Organic_modifier', 'Buffer', 'SMILES']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "\t\t('float', [])     : 1084 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('int', ['bool']) :   56 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "\t0.9s = Fit runtime\n",
      "\t1142 features in original data used to generate 1142 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.56 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 509, Val Rows: 128\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-0.9124\t = Validation score   (root_mean_squared_error)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.0226\t = Validation score   (root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.42994\n",
      "[2000]\tvalid_set's rmse: 0.427653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4252\t = Validation score   (root_mean_squared_error)\n",
      "\t4.16s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.41949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4194\t = Validation score   (root_mean_squared_error)\n",
      "\t4.51s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.4444\t = Validation score   (root_mean_squared_error)\n",
      "\t3.48s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.4067\t = Validation score   (root_mean_squared_error)\n",
      "\t187.6s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.4128\t = Validation score   (root_mean_squared_error)\n",
      "\t1.44s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t-0.919\t = Validation score   (root_mean_squared_error)\n",
      "\t2.75s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.2952\t = Validation score   (root_mean_squared_error)\n",
      "\t10.77s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-0.9742\t = Validation score   (root_mean_squared_error)\n",
      "\t2.3s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t-0.4338\t = Validation score   (root_mean_squared_error)\n",
      "\t11.72s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.2753\t = Validation score   (root_mean_squared_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 232.59s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"feature_engineered_models_median\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val    fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -0.275307       0.083018   19.947774                0.001000           0.247057            2       True         12\n",
      "1               XGBoost  -0.295230       0.013002   10.771411                0.013002          10.771411            1       True          9\n",
      "2              CatBoost  -0.406664       0.040009  187.595163                0.040009         187.595163            1       True          6\n",
      "3         ExtraTreesMSE  -0.412778       0.035008    1.440272                0.035008           1.440272            1       True          7\n",
      "4              LightGBM  -0.419354       0.011002    4.505034                0.011002           4.505034            1       True          4\n",
      "5            LightGBMXT  -0.425210       0.015004    4.158708                0.015004           4.158708            1       True          3\n",
      "6         LightGBMLarge  -0.433847       0.012003   11.723716                0.012003          11.723716            1       True         11\n",
      "7       RandomForestMSE  -0.444446       0.034008    3.478091                0.034008           3.478091            1       True          5\n",
      "8        KNeighborsUnif  -0.912399       0.021005    0.102023                0.021005           0.102023            1       True          1\n",
      "9       NeuralNetFastAI  -0.919033       0.420095    2.746630                0.420095           2.746630            1       True          8\n",
      "10       NeuralNetTorch  -0.974233       0.201046    2.295519                0.201046           2.295519            1       True         10\n",
      "11       KNeighborsDist  -1.022629       0.022005    0.163541                0.022005           0.163541            1       True          2\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'LGBModel', 'XTModel', 'RFModel', 'KNNModel', 'TabularNeuralNetTorchModel', 'XGBoostModel', 'CatBoostModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "('float', [])     : 1084 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "('int', ['bool']) :   56 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'CatBoost': 'CatBoostModel', 'ExtraTreesMSE': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -0.9123987573199117, 'KNeighborsDist': -1.022628963368709, 'LightGBMXT': -0.4252102525488757, 'LightGBM': -0.41935401819282764, 'RandomForestMSE': -0.44444566316458683, 'CatBoost': -0.40666420853287144, 'ExtraTreesMSE': -0.41277837369720743, 'NeuralNetFastAI': -0.9190325537977508, 'XGBoost': -0.2952300378604166, 'NeuralNetTorch': -0.9742330644709619, 'LightGBMLarge': -0.4338466090316968, 'WeightedEnsemble_L2': -0.2753069283479916}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': 'feature_engineered_models_median\\\\models\\\\KNeighborsUnif\\\\', 'KNeighborsDist': 'feature_engineered_models_median\\\\models\\\\KNeighborsDist\\\\', 'LightGBMXT': 'feature_engineered_models_median\\\\models\\\\LightGBMXT\\\\', 'LightGBM': 'feature_engineered_models_median\\\\models\\\\LightGBM\\\\', 'RandomForestMSE': 'feature_engineered_models_median\\\\models\\\\RandomForestMSE\\\\', 'CatBoost': 'feature_engineered_models_median\\\\models\\\\CatBoost\\\\', 'ExtraTreesMSE': 'feature_engineered_models_median\\\\models\\\\ExtraTreesMSE\\\\', 'NeuralNetFastAI': 'feature_engineered_models_median\\\\models\\\\NeuralNetFastAI\\\\', 'XGBoost': 'feature_engineered_models_median\\\\models\\\\XGBoost\\\\', 'NeuralNetTorch': 'feature_engineered_models_median\\\\models\\\\NeuralNetTorch\\\\', 'LightGBMLarge': 'feature_engineered_models_median\\\\models\\\\LightGBMLarge\\\\', 'WeightedEnsemble_L2': 'feature_engineered_models_median\\\\models\\\\WeightedEnsemble_L2\\\\'}, 'model_fit_times': {'KNeighborsUnif': 0.10202288627624512, 'KNeighborsDist': 0.16354107856750488, 'LightGBMXT': 4.158707857131958, 'LightGBM': 4.5050342082977295, 'RandomForestMSE': 3.478091239929199, 'CatBoost': 187.59516286849976, 'ExtraTreesMSE': 1.440272331237793, 'NeuralNetFastAI': 2.7466299533843994, 'XGBoost': 10.771410703659058, 'NeuralNetTorch': 2.2955193519592285, 'LightGBMLarge': 11.723716497421265, 'WeightedEnsemble_L2': 0.2470569610595703}, 'model_pred_times': {'KNeighborsUnif': 0.021004676818847656, 'KNeighborsDist': 0.022005081176757812, 'LightGBMXT': 0.015003681182861328, 'LightGBM': 0.011002063751220703, 'RandomForestMSE': 0.034008026123046875, 'CatBoost': 0.040008544921875, 'ExtraTreesMSE': 0.03500819206237793, 'NeuralNetFastAI': 0.42009544372558594, 'XGBoost': 0.013002157211303711, 'NeuralNetTorch': 0.20104575157165527, 'LightGBMLarge': 0.012002706527709961, 'WeightedEnsemble_L2': 0.0010001659393310547}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'CatBoost': {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}, 'ExtraTreesMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val    fit_time  \\\n",
      "0   WeightedEnsemble_L2  -0.275307       0.083018   19.947774   \n",
      "1               XGBoost  -0.295230       0.013002   10.771411   \n",
      "2              CatBoost  -0.406664       0.040009  187.595163   \n",
      "3         ExtraTreesMSE  -0.412778       0.035008    1.440272   \n",
      "4              LightGBM  -0.419354       0.011002    4.505034   \n",
      "5            LightGBMXT  -0.425210       0.015004    4.158708   \n",
      "6         LightGBMLarge  -0.433847       0.012003   11.723716   \n",
      "7       RandomForestMSE  -0.444446       0.034008    3.478091   \n",
      "8        KNeighborsUnif  -0.912399       0.021005    0.102023   \n",
      "9       NeuralNetFastAI  -0.919033       0.420095    2.746630   \n",
      "10       NeuralNetTorch  -0.974233       0.201046    2.295519   \n",
      "11       KNeighborsDist  -1.022629       0.022005    0.163541   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.001000           0.247057            2       True   \n",
      "1                 0.013002          10.771411            1       True   \n",
      "2                 0.040009         187.595163            1       True   \n",
      "3                 0.035008           1.440272            1       True   \n",
      "4                 0.011002           4.505034            1       True   \n",
      "5                 0.015004           4.158708            1       True   \n",
      "6                 0.012003          11.723716            1       True   \n",
      "7                 0.034008           3.478091            1       True   \n",
      "8                 0.021005           0.102023            1       True   \n",
      "9                 0.420095           2.746630            1       True   \n",
      "10                0.201046           2.295519            1       True   \n",
      "11                0.022005           0.163541            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          12  \n",
      "1           9  \n",
      "2           6  \n",
      "3           7  \n",
      "4           4  \n",
      "5           3  \n",
      "6          11  \n",
      "7           5  \n",
      "8           1  \n",
      "9           8  \n",
      "10         10  \n",
      "11          2  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: root_mean_squared_error on test data: -0.4565106858728858\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.4565106858728858,\n",
      "    \"mean_squared_error\": -0.20840200631613276,\n",
      "    \"mean_absolute_error\": -0.18747171298562215,\n",
      "    \"r2\": 0.8425708096313698,\n",
      "    \"pearsonr\": 0.9241670426072777,\n",
      "    \"median_absolute_error\": -0.04493602275848385\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_mean_squared_error': -0.4565106858728858, 'mean_squared_error': -0.20840200631613276, 'mean_absolute_error': -0.18747171298562215, 'r2': 0.8425708096313698, 'pearsonr': 0.9241670426072777, 'median_absolute_error': -0.04493602275848385}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x2f944211040>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.autogluon_fit_train_test (train, test, 'feature_engineered_models_median') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18095925",
   "metadata": {},
   "source": [
    "# classifier based descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af974a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = pd.read_csv(\"data/multiRT/MultiRT_hilic_descriptors.csv\", engine='python')\n",
    "mixed_descriptors = descriptors.select_dtypes(exclude=['integer','floating','boolean'])\n",
    "numeric_descriptors = descriptors.select_dtypes(exclude=['object','boolean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07daedfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AATS7dv</th>\n",
       "      <th>AATS8dv</th>\n",
       "      <th>AATS7d</th>\n",
       "      <th>AATS8d</th>\n",
       "      <th>AATS7s</th>\n",
       "      <th>AATS8s</th>\n",
       "      <th>AATS7Z</th>\n",
       "      <th>AATS8Z</th>\n",
       "      <th>AATS7m</th>\n",
       "      <th>AATS8m</th>\n",
       "      <th>...</th>\n",
       "      <th>MDEC-44</th>\n",
       "      <th>MDEO-11</th>\n",
       "      <th>MDEO-12</th>\n",
       "      <th>MDEO-22</th>\n",
       "      <th>MDEN-11</th>\n",
       "      <th>MDEN-12</th>\n",
       "      <th>MDEN-13</th>\n",
       "      <th>MDEN-22</th>\n",
       "      <th>MDEN-23</th>\n",
       "      <th>MDEN-33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.652174</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>2.681159</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>7.652174</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>22.348194</td>\n",
       "      <td>5.854464</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>2.242774</td>\n",
       "      <td>1.902439</td>\n",
       "      <td>2.242774</td>\n",
       "      <td>2.134146</td>\n",
       "      <td>2.672447</td>\n",
       "      <td>2.327236</td>\n",
       "      <td>12.254335</td>\n",
       "      <td>10.347561</td>\n",
       "      <td>41.331139</td>\n",
       "      <td>34.430214</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.24264</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>836 rows  183 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      AATS7dv   AATS8dv    AATS7d    AATS8d    AATS7s    AATS8s     AATS7Z  \\\n",
       "0    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "1    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "2    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "3    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "4    1.043478  0.000000  1.652174  1.300000  2.681159  1.800000   7.652174   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "831  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "832  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "833  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "834  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "835  2.242774  1.902439  2.242774  2.134146  2.672447  2.327236  12.254335   \n",
       "\n",
       "        AATS8Z     AATS7m     AATS8m  ...  MDEC-44   MDEO-11  MDEO-12  \\\n",
       "0     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "1     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "2     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "3     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "4     3.200000  22.348194   5.854464  ...      NaN       NaN      NaN   \n",
       "..         ...        ...        ...  ...      ...       ...      ...   \n",
       "831  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "832  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "833  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "834  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "835  10.347561  41.331139  34.430214  ...      NaN  0.814325      NaN   \n",
       "\n",
       "     MDEO-22  MDEN-11  MDEN-12  MDEN-13  MDEN-22   MDEN-23  MDEN-33  \n",
       "0        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "1        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "2        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "3        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "4        NaN      NaN      NaN      NaN      NaN       NaN      NaN  \n",
       "..       ...      ...      ...      ...      ...       ...      ...  \n",
       "831      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "832      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "833      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "834      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "835      NaN      NaN      NaN      NaN  4.24264  0.421637      NaN  \n",
       "\n",
       "[836 rows x 183 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_descriptors = mixed_descriptors.apply(pd.to_numeric, errors='coerce',downcast='float')\n",
    "cb_descriptors.dropna(axis = 1, how = 'all', inplace = True)\n",
    "cb_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "959bc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in range (len(cb_descriptors.columns)):\n",
    "    subset = cb_descriptors.iloc[:, col]\n",
    "    y_train = []\n",
    "    x_train = pd.DataFrame()\n",
    "    x_test = pd.DataFrame()\n",
    "    for row in range (len(subset)):\n",
    "        label = cb_descriptors.iloc[row, col]\n",
    "        if pd.isnull(cb_descriptors.iloc[row, col]) == False:\n",
    "            y_train.append(label)\n",
    "            x_train_new = numeric_descriptors.iloc[row, :]\n",
    "            x_train = x_train.append(x_train_new, ignore_index=True)\n",
    "        else:\n",
    "            x_test_new = numeric_descriptors.iloc[row,:]\n",
    "            x_test = x_test.append(x_test_new, ignore_index=True)\n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_test)\n",
    "    count = 0\n",
    "    for row_2 in range (len(subset)):\n",
    "        if pd.isnull(cb_descriptors.iloc[row_2, col]) == True:\n",
    "            cb_descriptors.iloc[row_2, col] = y_pred[count]\n",
    "            count +=1\n",
    "cb_descriptors.to_csv('cb_descriptors.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f7e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors.update(cb_descriptors)\n",
    "descriptors = descriptors.select_dtypes(exclude=['boolean', 'object'])\n",
    "descriptors = descriptors.astype('float64')\n",
    "data = pd.concat([hilic, descriptors],axis =1)\n",
    "data = data_prep.dataset_prep(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04061fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAFACAYAAAD3bNicAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA3W0lEQVR4nO3deZhU1bX38e+ChgYaEJRBJmk1hKsQHCDqFfWiMVFDIuIEqIiAgEaNOAFCEglXIvqCiSROOCIiMgeuxhHRmDiBiAMSFBERQUEBGRoaunu9f9TppGgauhq66pyq+n2ep56q2nXOWauU7tVnn332NndHREQkKqqFnYCIiEg8FSYREYkUFSYREYkUFSYREYkUFSYREYkUFSYREYkUFSaRKmBmbmYXhpxDfpBHpzDzEDlQpvuYJNOY2eNAI3f/RaqObWaHAhvdvbCqY+4lj1eBj9z92ri26kBj4Ft3L0pFHiLJkBN2AiKVYWY13X1n2HmU5e5fRyCHYiD0PEQOlLryJNLM7FUzu9/MxprZeuCfZna0mT1rZlvMbJ2ZTQnOWDCzkUAfoGvQreVm1iX4rIWZPW1mG4PHs2bWJi7WSDP7yMx6mtlnwfH/amaNEjj2bl15ZvYjM3vZzLab2QYze9zMDor7/HEze8bMrjezr4J8HjOzOgn8N3kc+B/gmrg88st25ZlZl+D9OWb2bpDL62bW0sz+x8zeN7OtQR6HlInR18w+NrMdZvaJmd1gZvp9ISmhf2iSDi4DDDgV+DXwd+Aj4ATgTKAuMDf4xTkWmAa8DDQLHm8Ev/DnAzuI/VL/b2At8HKZYpAP9AC6Az8DjgNGB5+Ve+yyyQbHex7YGuTYHTgZeLTMpqcC7YPvUBrz+gT+e1wPvAk8FpfHl/vY/vfAYOBEoCEwFfgdMBDoArQDRsblPwD4Q7DNUcBNwFDgVwnkJnLA1JUn6eBzd78JwMxGAe+7+9DSD83scmAD0Mnd3zGz7UBhfPeamZUWt74eXFg1s0HAOuAXxAoOxH4mrnD374NtJgB9Adx9a3nHLselxIplb3ffEhxnIDDfzH7g7suD7TYDVwfXg5aa2XTgJ8Ad+/qP4e7fm9lOoKDMd9zbLr9199eDbR4A/gx0dPdFQdtEIH7gxm+BIe4+I3j/uZmNIVaY/rKv3ESqggqTpIN34153BE4zs63lbHck8M5ejtEROBzYUuYXeJ1gv1JflBalwBqgSSXzPQr4oLQoBd4ASoCjgdLC9HGZQQpriJ3VVLUP4l5/Ezx/WKatCYCZNQZaAQ+a2f1x2+QQK+wiSafCJOlgW9zrasCzwM3lbPdNOW3x+y0Gepbz2Ya417vKfOZUvsvbgv3KE99eFbESER/HAdy9bFtp3NLnqyinm1IkFVSYJN0sAi4mdmZT9hd7qZ1A9XL260VsKPWmA4hf3rHL+hjoZ2b14s6aTib2S3/pAcSubB6V5u7fmNlXwJHu/kRVH18kERr8IOnmXuAgYKqZnWhmR5jZmWY2wczqBdusBNqbWVsza2RmNYDJxM6o5gQj0g43s9PMbFz8yLwElHfssiYTO8t7IhiddxrwIDAr7vrSgVoJnBCMxGtUxSPmRgJDgpF4bc2svZldbma3VmEMkb1SYZK04u5rgM7Ertc8DywhVqwKgwfAQ8TOTBYC64HO7l4AnAasAKYD/wImEhultrESKexx7HJyLADOAuoTu+Y1h9goun6ViFORscTOmj4O8jisqg7s7g8Ty7U38D7wOrERfJ9XVQyRfdHMDyIiEik6YxIRkUjR4AeRiDGzw4h10e3N0e6+KlX5iKSauvJEIsbMcojNQLE3KzVJq2QyFSYREYmUjOnKq1atmteuXTvsNNLSrl27qFGjvFHPmR1bRKCgoMDdPVLjDTKmMNWuXZtt27ZVvKHsoXnz5qxZsybrYosIBPM/RkqkqqSIiIgKk3DEEUdkZWwRiaaMGfyQl5fn6soTEakcMytw97yw84inMybhsssuy8rYIhJNKkzCK6+8kpWxRSSaVJhEpFyTJ08mPz+fatWqkZ+fz+TJk8NOSUIQzDC/OO6x2cwGJzNmxgwXl/3Xo0ePrIwtezd58mQGDhxIQUEBAF988QUDBw4E4NJLLw0zNUkxd18GHAtgZtWBr4DZyYypwQ8SmsGDB7N48eKw05ByvPXWWxQWFu7Rnpuby0knnRRCRrIvxx57LH/605/2a9/KDH4ws58Bt7n7Hsu9VCV15Qlt27YNLfY777wTWmzZu/KK0r7aJa3lmNnCuMfAfWzbE5iS7IRScsZkZm2BqXFNRwC/A54I2vOJrch5sbtvDPa5FegPFAO/dvcX9hXjQM+Y8oc9u9/7prudTwzQzA+ym8MOO4wvv/xyj/bWrVuzcuXK1CckSZPoGZOZ1QTWAO3c/Ztk5pSSMyZ3X+bux7r7sUBHoIBYH+UwYJ67twHmBe8xs6OJVeZ2wNnAfUHfpogk2ZYtW6hXrx65ubm7tdepU4fRo0eHlJVEwDnAomQXJQinK+8nwGfu/gXQjdjy1gTP5wWvuwFPu3uhu38OLAdOSHWi2WLs2LFZGVv2tHXrVrp37864ceN45JFHaN26NWZG69atmTBhggY+ZLdepKAbD8IZlRffR9nU3dcCuPtaM2sStLcA3orbZ3XQtpugL3QgQM2aNZOWcKY7/vjjszK27G7btm2cf/753HDDDZx99tmARuBJjJnVAX4KDEpFvJSeMQV9lOcC0yvatJy2PS6GufsEd+/k7p1ycjTyfX+dccYZWRlb/qOgoIALLriAa6+9lq5du4adjkSMuxe4+yHu/n0q4qW6K69sH+U3ZtYMIHheF7SvBlrF7deS2EU3Eali27dv58ILL2TQoEGce+65YacjkvLCVLaPci7QJ3jdB5gT197TzHLN7HCgDaBxxSJVbMeOHVx88cX07duX7t27h52OCJDCa0x76aMcA0wzs/7AKuAiAHdfYmbTgI+BIuAady9OVa7Z5rXXXsvK2NmusLCQHj16cOmll3LRRReFnY7Iv6XsjKm8Pkp3/87df+LubYLnDXGfjXb3I929rbs/l6o8s9Hbb7+dlbGz2c6dO+nVqxcXX3wxPXv2DDsdkd1o5gdhyJAhWRk7W+3atYtLL72Ubt26adSdRJIKk0gWKSoqonfv3pxzzjn06dOn4h1EQqDCJDRo0CArY2eboqIi+vTpwxlnnEG/fv3CTkdkr1SYhI8//jgrY2eT4uJi+vXrxymnnPLv5StEokqFSbj++uuzMna2KCkp4corr+THP/4xV199ddjpiFRIhUmYPr2iiTgyM3Y2KCkpYeDAgXTo0IHrrrsu7HREEqLCJJKhSkpKuPrqq2nbti033HBD2OmIJEyFSfjpT3+albEzmbtz3XXXkZ+fzy233BJ2OiKVoqXVA9m8UODKMZq0M5O4O4MHD6ZRo0b89re/DTsdibjKLK2eKjpjEk4++eSsjJ2J3J2bbrqJBg0aqChJ2lJhklCXytYy3VXH3Rk6dCi1a9dm5MiRYacjst9UmEQygLszYsQIzIzbb78ds/KWNBNJD1pdTxg+fHhWxs4kI0eOpLCwkLFjx6ooSdpTYRJ69OiRlbEzxahRo9i0aRN/+tOfVJQkI6grTzjmmGOyMnYm+MMf/sA333yjoiQZRWdMImnqrrvuYtWqVdx3330qSpJRVJhE0tDdd9/NJ598woQJE6hWTR0fkllUmITZs2dnZex0NX78eD788EMeeeQRFSXJSCpMwnfffZeVsdPRvffey8KFC3nsscdUlCRj6V+2cOWVV2Zl7HTz4IMP8sYbb/DYY49RvXr1sNMRSZqUFSYza2BmM8zsX2a21Mz+28wONrOXzOzT4Llh3Pa3mtlyM1tmZmelKk+RKHrkkUeYP38+EydOVFGSjJfKM6Z7gOfd/b+AY4ClwDBgnru3AeYF7zGzo4GeQDvgbOA+M9NPo2SliRMn8vzzzzNp0iRyctT7LpkvJYXJzOoDpwGPALj7TnffBHQDJgabTQTOC153A55290J3/xxYDpyQilyz0ZdffpmVsdPBk08+ydy5c5k8eTI1atQIOx2RlEjVGdMRwHrgMTN7z8weNrM8oKm7rwUInpsE27cA4n9jrQ7admNmA81soZktLCoqSu43yGC33357VsaOuqeffpoZM2YwZcoUatasGXY6IimTqsKUAxwP3O/uxwHbCLrt9qK8uwX3WDjK3Se4eyd376Qujv334IMPZmXsKJs+fTpPPfUUU6dOVVGSrJOqwrQaWO3ubwfvZxArVN+YWTOA4Hld3Pat4vZvCaxJUa4ioZo1axaPP/4406ZNIzc3N+x0RFIuJYXJ3b8GvjSztkHTT4CPgblAn6CtDzAneD0X6GlmuWZ2ONAGeCcVuWaj448/PitjR9GcOXN46KGHmDFjBrVq1Qo7HZFQpLL/6zpgspnVBFYAfYkVxmlm1h9YBVwE4O5LzGwaseJVBFzj7sUpzDWrPPPMM1kZO2qeeeYZ7rvvPmbPnk3t2rXDTkfk38ysAfAw0J7YZZV+7v5m0uK573HpJi3l5eX5tm3b9nv//GHPVmE26aX9R/eHViB+8YtfqDgBzz//POPGjWP27NnUrVs37HQki5hZgbvnVbDNROB1d384OLmoE4ysTgqNGBAWLVqUlbGj4qWXXmLs2LEqShJJcbf7XAGx232AncmMqSmJREL0yiuvcMcddzBr1izq1asXdjqSnXJKb7sJHgPLfL63232SRoVJGDRoUFbGDttrr73GqFGjmDVrFvXr1w87HcleRaW33QSPCWU+r+ztPgdM15gC2XyN6bPRZ4c2/1pxcXFWzv32+uuvM2LECObMmUPDhg0r3kEkSSq6xmRmhwJvuXt+8P5UYJi7d01WTjpjElq1alXxRhkYOyxvvPEGw4cPZ/bs2SpKEnn7uN0naTT4QSSF3n77bYYMGcJf//pXDjnkkLDTEUlUebf7JI0Kk0iKLFiwgBtvvJHZs2fTqFGjsNMRSZi7LwY6pSqeCpPw8MMPZ2XsVFq0aBHXX389s2fPpkmTJhXvIJLFdI1JQu1SyoburMWLF3Pttdcyc+ZMmjZtGnY6IpGnwiR07949K2OnwocffsjVV1/N9OnTadasWdjpiKQFdeWJJMmSJUsYMGAA06dPp0WLPZYTE5G90BmTSBIsXbqU/v37M3Xq1KwcEi9yIFSYhPfffz8rYyfLsmXL6Nu3L1OmTKF169ZhpyOSdlSYhKlTp2Zl7GRYvnw5ffr0YfLkyRx++OFhpyOSllSYhD/84Q9ZGbuqrVixgssuu4xJkyZx5JFHhp2OSNpSYRKpAitXruSSSy5h4sSJtGnTJux0RNKaCpOQn5+flbGryqpVq+jVqxePPvoobdu2rXgHEdknFSbhjTfeyMrYVWH16tX06NGDhx56iKOPPjrsdEQyggqT0KdPn6yMfaDWrFnDxRdfzIMPPkj79u3DTkckY6gwCS+99FJWxj4QX3/9NRdeeCH33nsvHTp0CDsdkYySssJkZivN7EMzW2xmC4O2g83sJTP7NHhuGLf9rWa23MyWmdlZqcpTpCLr1q3jggsu4M9//jPHHXdc2OmIZJxUnzGd7u7Hunvp9OnDgHnu3gaYF7zHzI4GegLtgLOB+8ws+5Y5TZGLLrooK2Pvj/Xr13P++efzxz/+kY4dO4adjkhGCrsrrxswMXg9ETgvrv1pdy9098+B5cAJqU8vO9xzzz1ZGbuyvvvuO84//3zGjh3LCSfon6NIsqSyMDnwopm9a2YDg7am7r4WIHguXaimBfBl3L6rg7bdmNlAM1toZguLioqSmHpmC3M0WbqMZNuwYQPdu3dnzJgxnHTSSWGnI5LRUjm7eGd3X2NmTYCXzOxf+9jWymnzPRrcJwATAPLy8vb4XBKzadOmrIydqE2bNnH++edz++2307lz57DTEcl4KTtjcvc1wfM6YDaxrrlvzKwZQPC8Lth8NRA/JXNLYE2qchUp9f3339O9e3dGjhzJaaedFnY6IlkhJYXJzPLMrF7pa+BnwEfAXKD0RpY+wJzg9Vygp5nlmtnhQBvgnVTkmo3uuuuurIxdkc2bN9O9e3dGjBhBly5dwk5HJGukqiuvKTDbzEpjPuXuz5vZAmCamfUHVgEXAbj7EjObBnwMFAHXuHtxinLNOieeeGJWxt6XrVu3cv755zN06FDOPPPMsNMRySrmnhmXZvLy8nzbtm37vX/+sGerMJv0svOJAaxZE05PafPmzUOLvTfbtm2je/fuDB48mJ///OdhpyOSVGZW4O55YecRL+zh4iKRUlBQwAUXXMB1112noiQSEhUmkcD27du58MILGTRoEL/85S/DTkckayVUmMxsxF7ab63adCQMr7zySlbGjrdjxw4uuugi+vXrR/fu3cNORySrJXrGNHQv7bdUVSISnkWLFmVl7FKFhYX06NGD3r17c+GFF4adjkjW22dhMrPmZtYcqGZmzUrfB4//AQpTk6Yk080335yVsQF27txJz5496dGjBz169Ag1FxGJqWi4+Gr+M+PC6rh2A4qB3yYjKZFU2LVrF5dccgndu3fnkksuCTsdEQlUVJgOJ1aEFgPHxLWXAOvdfUeS8pIUqlevXtbFLioq4rLLLqNr165cfvnloeQgIuXbZ2Fy9y+Clw2Sn4qEZdmyZVkVu6ioiMsvv5wzzzyTvn37pjy+iOxbwsPFzey/zew6Mxse/0hmcpIaN9xwQ9bELi4upm/fvpx22mkMGDAgpbFF0lV5C70mNV4iMz+Y2UhgOLEuvfjpFdzdz0hKZpWkmR/2X7bM/FBcXEz//v3p1KkT1157bUpiikRdIjM/mNlKoJO7f5uKnBKdK+8q4BR310SqkpZKSkoYOHAgxx57rIqSSMQl2pVnQNJP3yQcZ5wR3klvKmKXlJRw9dVXc/TRRzN48OCkxxNJMzmlC64Gj4HlbFPeQq9Jk2hX3mhgpbs/lOyE9pe68vbfyjFdw04hadyda665htatWzN06N7uExfJXgl25TWPX+gVuM7d/56snBI9YzoR+Etw8evF+EeyEpPUOeWUUzIytrtz/fXX06JFCxUlkQOwl4VekybRa0yvBw/JQCtWrMi42O7OjTfeyCGHHMKIEeVO9SgiCQgWd63m7lviFnodlcyYCRUmd/99MpMQqUruzpAhQ6hbty6/+93vwk5HJN2Vu9BrMgMmVJjM7OS9febub1RdOhKGMLu5qjq2uzN8+HBycnIYNWoUwQ+TiOwnd1/B7jP/JF2iXXn/KKetdNRE9SrKRULSu3fvjIl92223UVRUxF133aWiJJKmEu3K222QRDDj+O3AM8lISlKrffv2od1gW5WxR40axZYtW7j77rtVlERCZma1gDbAbhNiJtLLlugZ026CYYPXA4uAWftzDJGqNHr0aNavX8/48eNVlERCZmbnAhOBg8p85CTQy3YgS6vnAk0qs4OZVTez98zsmeD9wWb2kpl9Gjw3jNv2VjNbbmbLzOysA8hTMtydd97JV199paIkEh3jgN8Ddd29WtwjoUs/iQ5+KDtZax7QjdiNVpVxPbAUqB+8HwbMc/cxZjYseD/UzI4GegLtgObAy2b2Q3cvrmQ8ScCMGTPSNva4ceP47LPPeOCBB1SURKKjqbv/aX93TvSM6adlHh2A6UC/RAOZWUugK/BwXHM3Yqd7BM/nxbU/7e6F7v45sJwk39CVzbZs2ZKWse+55x6WLFnCAw88QLVqB3LyLyJV7EUzO2l/d0508MPp+xsgzp+AIex+Iaypu68NYqwNprsAaAG8Fbfd6qBNkqBv376hDX7Y39j33nsvixYt4tFHH1VREomelcBcM5sKrI3/wN3/UNHOCQ9+sFg/yQlAK2AVsMATmWgvtu8vgHXu/q6ZdUlkl3La9ogVTCY4EKBmzZqJpCIZ4IEHHuDNN99k4sSJVK+uuxVEIqgjsARoHzxKOVA1hcnMWgH/BxwFrCM26GGpmZ3r7qsSOERn4Fwz+zlQC6hvZk8C35hZs+BsqVlwbIidIbWK278lsMef1e4+AZgAsUlcE/kukt4efvhhXnvtNSZNmqSiJBJRB9rLlmgfyD3AAuBgd28FHAK8DYxPZGd3v9XdW7p7PrFBDa+4+2XAXKBPsFkfYE7wei7Q08xyzexwYmPhtRZUknzxxRdpEfuxxx7jxRdf5IknniAnZ7/udBCRNJBoYToF+LW7bwNw963ADcBepypK0Bjgp2b2KbFBFWOC4y8BpgEfA88D12hEXvLceeedkY89adIknnnmGSZPnkyNGjWSnJWIHAgza2xmk83sazMrjn8ktH+C6zGtAk5w96/j2poRu87Ucr+zr0Jaj2n/RX1p9SlTpjBt2jSmTp2qa4kiVSyR9Zj245hTgGbA/wOmAL2I3Q40zd3/XNH+iZ4xzSY2u+wZZna4mZ0BzABm7l/aIomZNm0aU6ZM4emnn1ZREkkfZwAXu/uzQEnwfCmQ0OSYiRamYcAHxObG+wx4FvgIuLXS6UrkHHvssZGMPXPmTJ544gmmTZtGbm5u6pISkQNVA1gfvN5uZnnBQLn/SmTnRO9j2g4MMrOrgMbA+kSHikv0/e1vf4tc7Dlz5vDII48wc+ZMatWqleKsROQAfQIcD7wLvA8MN7PvgW8S2TmhMyYzO9nMjvCYde7uZnbEvtZpkvTRrVu3SMV+5plnuP/++5kxYwa1a9cOISsROUDDic2nCjACuIjYgLkbE9k50TG3D/Kf6YJKWdD+owSPIRG1YMGCyMR+7rnnGD9+PLNnz6ZOnTohZSUiB8LdX4l7/S7ww8rsn+g1ptbu/lmZwJ8BrSsTTGRfXnzxRcaNG8fMmTPJy6vSQUIikmJmdpCZXWJmQ4L3hwZr+VUo0cK03swOKxO0NbChcqlKFA0YMCD02PPmzWPMmDHMmjWLevXqVbCXiESZmR1PbPLtYcBvg+YOQIVDxSHx+5jGAj8GBgGfEpuJ4T5gsbsn1GeYbLqPaf+tHNM11Pivvvoqv//97/nrX//KQQeVXVdMRJIpSfcxvQ486u6PmdlGd29oZnWBZe5e4YTciV5jug14lNhMDKWVbAb/qYSSxhK5yTVZGjVqRLt27ZgzZ46KkkjmaAc8Hrx2iM0YZGYJFcCEuvLcfZu79wCaAicBh7p7j9IpikT2xz//+U+2bNnC7NmzadCgQdjpiEjVWQ+UvfzzA+CrRHau1EI27r7e3Re4+/qKtxbZu7feeothw4bRsGFDDj744LDTEZGqNRF42sxOIbZqUkdii8Q+lMjOmqJZmDBhQkrjLViwgJtvvpnZs2fz9ttvpzS2iKTEnUBd4G/B86vEVqlIaPCDCpPQpEmTijeqIu+++y6DBw9m1qxZNG7cOKWxRSQ1gtUghhOb8aGRu39bmf1VmITzzjsvJYMfFi9ezHXXXcesWbNo2rRpSmOLSPKZ2Yq9tP/7tbsfUdFxVJgkJT744AN+9atfMWPGDA499NCw0xGR5MgnNnr7MeDrfW+6d4kurZ4H/BroBOx296O7/2x/g0t2+Oijjxg0aBDTp0+nefOEbvwWkfR0EjCA2Px4rxIb7PB8ZSf9TvSM6VHgOOCvgIaIZ5hFixYl7dhLly5lwIABTJ06lZYt91xTMpmxRSS13P0d4B0zu4HY4oCjgAfM7GFgvLt/n8hxEh0u/jOgs7sPcfffxz/2K3uJlJkzk7Pe47Jly+jbty9TpkzhsMMOK3ebZMUWkfC4+1Z3f4jYGdRjxCZp6Jjo/okWpu+ArZVPT9LB6NGjq/yYn376KX369OGpp54iPz8/pbFFJFxmlm9mtwNfAD8FrgT+mej+iRam4cB4M9OdkFKhFStW0Lt3byZNmsQRR1Q4AEdE0oCZVTez98zsmX1sc6GZvQC8A+QBZ7l7Z3d/3N0LE42V6DWmyUB1oJ+ZFcd/4O41Ew0m0dSqVasqO9bKlSu55JJLmDhxIm3atElpbBFJquuBpUD9fWwzjdiovAeAHUA3M9ttNVB3/0NFgRItTGcmuF25zKwW8HdiKxrmADPc/bbgDGwqsSGGK4GL3X1jsM+tQH+gGPi1u79wIDnI3lXV7AurVq2iV69ePPbYY7Rt2zalsUUkecysJdAVGM2+V6H9O7FJW0/dy+cOVE1hcvfXEtluHwqBM4LZZWsA/zCz54DzgXnuPsbMhhFbu2OomR0N9CQ2Q21z4GUz+2FwN7FUsSuuuILHH3+80vtNnjyZESNGsGrVKpo3b06tWrWYM2cORx11VNJji0iVyTGzhXHvJ7h72XnK/gQMocztQmW5e5cqSWhvH5jZRe4+PXh9yT4SeaqiIMEY9tLBEzWChwPdgC5B+0Ri496HBu1PB32Sn5vZcuAE4M2KYknlvfjii5XeZ/LkyQwcOJCCggIAvvrqK2rVqsXixYtp165dUmOLSJUqcvdOe/vQzH4BrHP3d82sSyoS2tcZ023A9OD13oZOOVBhYYLYhTPgXeAHwL3u/raZNXX3tQDuvtbMSidOawG8Fbf76qCt7DEHAgMBatbUpa79seHlCRR+9x1dunSp1H5vvfUWhYW7X8vcsWMH/fv356GHEppAGIDNmzdXKq6IpFxn4Fwz+zlQC6hvZk+6+2XJCrjXwuTu7eNeH36ggYJuuGPNrAEw28za72NzK6dtjzuHg9PNCRBbwfZAc8xWjRo1qvQ+ZYtSRe17c+SRR1Y6toikjrvfCtwKEJwx3ZzMogQhzJXn7pvM7FXgbOAbM2sWnC01A9YFm60G4odrtQQ002cSHHzmQFaOmVPp/fLz8/niiy/2aG/dujWvvvpqFWQmItmqwvuYzOxMMxtsZidYzONm9r2ZvRaM1KiQmTUOzpQws9rERvn9C5gL9Ak26wOU/oacC/Q0s1wzOxxoQ2xcvCRBZa4JlRo8eDDVqu3+z6dOnTqVvmF2f2KLSDjc/VV3/0Wy4+yzMJnZ9cTmx7sEeAm4Fzic2A23DoxNME4zYL6ZfQAsAF5y92eAMcBPzexTYncHjwFw9yX8Zzz888A1GpGXPBs3bqzU9u7O/PnzGTVqFK1bt8bMaN26NRMmTODSSy9NamwRyXy2r0lfzewToHcwUKEzsTHqrdx9jZkdCrzn7s1SlOs+5eXl+bZt+z+/bP6wZ6swm/Sy84kBlVoTafr06bz55pvcfffdBxy7efPmWo9JJERmVuDueWHnEa+ia0yHuvvbAO7+TzPb4e5rgvdfB8thSJq74447Et5206ZNjBs3jpdffjnlsUUkOyQ6V16pyg25krRwyimnJLzt8OHDGTFiBHXr1k15bBHJDhWdMdU0s+Fx72uVeV8jCTlJip166qkJdae9+eabfPvtt/zyl79MeWwRyR4VFaa3iA1KKPV2mfdvIVlh165d3HLLLUydOjXsVEQkw+2zMFXVvEeS/saNG0evXr1o0WKPCThERKpUym+wleipaCDDZ599xgsvvFBlAx4qE1tEsk9lBz9IBvrggw/2+pm78+tf/5p77rmH6tWrpzS2iGQnFSbhxhv3vrzKlClTaN++PR06dEh5bBHJTurKk73asGED48ePZ968eWGnIiJZRGdMQl5e+fdJDx06lNtuu22vnycztohkLxUm4dNPP92j7fXXX2fr1q2cc845KY8tItlNhUm46aabdntfWFjI0KFD+eMf/5jy2CIiKkzClClTdnt/1113ccUVV3DooYemPLaIiAY/yG4++eQTXnvtNV588cWwUxGRLKUzJqFLly7A7vcslV0EMNmxRURKqTAJTz31FACTJk2iY8eOKV1VtjS2iEgpFSbhtNNO49tvv+X+++/nN7/5Tcpji4jEU2ESli9fzi233ML//u//Urt27ZTHFhGJp8Ik7Ny5k+LiYs4888ywUxERUWHKdl60k7p16zJu3LhQ4t9yyy2hxBWR6EpJYTKzVmY238yWmtkSM7s+aD/YzF4ys0+D54Zx+9xqZsvNbJmZnZWKPLPR929O56abbqJx48ahxL/iiitCiSsi0ZWqM6Yi4CZ3Pwo4CbjGzI4GhgHz3L0NMC94T/BZT6AdcDZwn5lV/ZoLWW7Xt19SuOZf3HHHHaHlkMoRgCKSHlJSmNx9rbsvCl5vAZYCLYBuwMRgs4nAecHrbsDT7l7o7p8Dy4ETUpFrtnAvYcPLD3LwmQPDTkVEZDcpv8ZkZvnAccDbQFN3Xwux4gU0CTZrAXwZt9vqoK3ssQaa2UIzW1hUVJTUvDPN1g9eJrflUdQ4pFXYqYiI7CalhcnM6gIzgcHuvnlfm5bT5ns0uE9w907u3iknR7MrJap42ya2ffAiB510MQBTp04NLZcwY4tINKWsMJlZDWJFabK7zwqavzGzZsHnzYB1QftqIP5P+ZbAmlTlmuk2zn+EBv9zOZZTA4Dt27eHlkuYsUUkmlI1Ks+AR4Cl7n533EdzgT7B6z7AnLj2nmaWa2aHA22Ad1KRa6bb/vl7UK06tQ77z1LpYY6M06g8ESkrVf1fnYHewIdmtjhoGw6MAaaZWX9gFXARgLsvMbNpwMfERvRd4+7FKco1Y5Xs2sGmfzxJkwtvCzsVEZG9Sklhcvd/UP51I4Cf7GWf0cDopCWVhb5/Yyr1jutK9dr1w05FRNKEmdUC/g7kEqsZM9w9qX/dauaHLLFz/Up2rltBXrvT9/hsxYoVIWQUfmwRSUghcIa7HwMcC5xtZiclM6AKUxZwL2HjvAkcfOYgYpf7dhfWdERhxxaRinnM1uBtjeCxxyjpqqTClAW2Ln6eWocdQ42Gzcv9/N57701xRtGILSKJMbPqwfiAdcBL7v52MuOpMGW4oq0b2LZkPvVPPD/sVEQkmnJKJyoIHntMB+Puxe5+LLFbd04ws/ZJTSiZB5fwbZz3EA26XIFVr7HXbX70ox+lMKPoxBYRAIrcvVMiG7r7JjN7ldgcph8lKyGdMWWw7Z8toFpuHrVa7nui1BdeeCFFGUUrtohUzMwam1mD4HVt4EzgX8mMqcKUoUp27mDTP5+mQZcrKtz2vPPOS3o+UYwtIglpBsw3sw+ABcSuMT2TzIDqystQ3//zKep3OpfqtepWuO0774Q3qUaYsUWkYu7+AbGJt1NGZ0wZaOc3K9j13ZfUOeq0sFMREak0FaYM4yXFbJg3gYZ7uWepPP369UtyVtGMLSLRZO5JvU8qZfLy8nzbtm37vX/+sGerMJvwbH73//CiQg468cKE91k5pmsSMxKRKDOzAnfPCzuPeDpjyiBFm7+l4F+vU7/TeZXar2XLlslJKOKxRSSaVJgyyMZ5E2h4en+seuXGtJSUlCQpo2jHFpFoUmHKEAWfvkX1ug3Jbd427FRERA6IClMGKCks4Ps3p9PgtMv3a//777+/ijNKj9giEk0qTBlg0+tPUv/E86mWu3/XL3WNSUSiRIUpzRWu/ZSizeuo88OT9/sYv/zlL6swo/SJLSLRpMKUxrykmI3zH+HgMwcmfM+SiEjUqTClsS0L51KnzUnk1G8SdioiIlVGhSlNFX2/joJP36JexwPvClu4cGEVZJR+sUUkmlJSmMzsUTNbZ2YfxbUdbGYvmdmnwXPDuM9uNbPlZrbMzM5KRY7pxN1j0w79ZABWrfoBH2/u3LlVkFX6xRaRaErVGdPjxBaWijcMmOfubYB5wXvM7GigJ9Au2Oc+Mzvw374ZpOCTN8g5qCm5h/6gSo43atSoKjlOusUWkWhKSWFy978DG8o0dwMmBq8nAufFtT/t7oXu/jmwHDghFXmmg5LCbWx+exYNTrk07FRERJIizGtMTd19LUDwXHoFvwXwZdx2q4O2PZjZwNJ16ouKipKabFRsfO0JDvrvi6mWW6fKjtmiRbn/eVMizNgiEk1RHPxQ3rjncqdAd/cJ7t7J3Tvl5GT+moeFX/2Lkm0bqdPmxCo97oIFC6r0eOkSW0SiKczC9I2ZNQMIntcF7auBVnHbtQTWpDi3yPHiIja++igNzxxY5cfu379/lR8zHWKLSDSFWZjmAn2C132AOXHtPc0s18wOB9oAWb/+9uaFf6XOf51KTr1GVX7s5557rsqPmQ6xRSSaUjVcfArwJtDWzFabWX9gDPBTM/sU+GnwHndfAkwDPgaeB65x9+JU5BlVuzZ9zfYV71LvuJ+HnYqISNKl5MKMu/fay0c/2cv2o4HRycsofbg7G19+kIPPqJp7lspz3nnnJeW4idhy6HEZs3qwSFgybRXqKA5+kDgFS/9OjUNaUbPpEUmLcd999yXt2BU55Ge/Ci22iESTClOEFe/YyuaFczmo8yVJjdOhQ4ekHn9f1jx6bWixRSSaVJgibNOrj9Ogcy+q1ayV1DjffvttUo+/LyXbN4cWW0SiSYUponasXkLJzgJqH9kp7FRERFJKhSmCvHgXm159nIZnXJmSeLfffntK4pSnwamXhRZbRKJJhSmCNr89i7x2p5NT9+CUxDv99NNTEqc8uYeFd31LRKJJhSlidm34ih2r3qfusWUnY0+ezp07pyxWWd9MHhJabBGJJhWmCHF3Nrw8gYY/GYiZ/teISHbSb78I2bZkPjWbHkHNxvlhpyIiEhoVpogo3r6ZLe89y0En90x57BdeeCHlMUs1uVgLBYrI7jJ/rYgI27pkPpv+/gTFm7/FauRS9/hfUK1GbsrzWLp0KT/60Y9SHhdg17df6gxRJMLMrBXwBHAoUAJMcPd7khlThSkkW5fMZ8Pzf8GLCgHwXTvY+u7/UbNxa+q2S+0ouUv6X82QRXkpjVlq4ysPkXfUqaHEFpGEFAE3ufsiM6sHvGtmL7n7x8kKqMIEDB48mK9nzUtpzMI1y6B4125tXlTId8+NZ+v7qe1aKyncltJ4IpI+ghXGS1cb32JmS4mtKq7ClHHKFKUK25PJkjNreWKha4QWW0QAyDGzhXHvJ7j7hPI2NLN84Djg7WQmZO7lrlqedvLy8nzbtv3/yz/VSy+svr8vxZvX79FevX5jWl79WEpzEZH0diDLXphZgbtX2JdvZnWB14DR7j5rvwMmQKPyQtLgtMuxnN0HOlhOLg1OuzzluWyc/2jKY0YhtogkxsxqADOByckuSqDCFJq67U7n4LOvpXr9xoBRvX5jDj772pQPfADY9vGrKY8ZhdgiUjEzM+ARYKm7352KmLrGFKK67U4PpRCJiFRCZ6A38KGZLQ7ahrv735IVUIVJyG3ZLitji0jF3P0fgKUyprryhMbdhmZlbBGJpkgXJjM728yWmdlyMxsWdj6Z6uspt2ZlbBGJpsgWJjOrDtwLnAMcDfQys6PDzSozFW34Kitji0g0RbYwAScAy919hbvvBJ4GuoWck4iIJFlkb7A1swuBs939yuB9b+BEd782bpuBwMDg7fHA9pQnmrgcYnNOZZpM/V6Qud9N3yu9JPt71Xb3SJ2kRHlUXnmjQHarosG0GeVOnRE1ZrbQ3TuFnUdVy9TvBZn73fS90kumfq99iVSVLGM10CrufUtgTUi5iIhIikS5MC0A2pjZ4WZWE+gJzA05JxERSbLIduW5e5GZXQu8AFQHHnX3JSGndSDSostxP2Tq94LM/W76XuklU7/XXkV28IOIiGSnKHfliYhIFlJhEhGRSFFhkgMSTImfMcyswgXTRCS5VJiSyMx+YGadzCy34q3Th5mdEtzwjLt7phQnM+sG3GlmTcLOpSqZ2Ulm1jt4rhl2PsmWKf8ey8rU71WeyI7KS3dm9gvgD8B3wNdmdpu7fxJyWgfEzKoBdYAHY28tz90fCIpTNXcvCTnF/WZm/wPcCVzn7uvCzqeqmNm5wO3Ae8Sm9LoV+DTUpKqYmZ0I1AIK3H1B6R9LnuYju8zseGI/bzvd/Z10/z6VoVF5SWBmJwOPAr3c/T0zuw+o5e79Qk6tSpjZEKAYOAZ4z93/GHJKB8zMbgSquftYM2sOtAM2A/9y9+/DzW7/mNkhwFPATe7+kZk9CjwHvAZsdvcdoSZYBczsHGA8MB9oAnzn7v2Dz9K2OAV/2P4v8CGxojvP3R8MN6vU0RlT8oxx9/eC17cBD5lZrrsXhplUFSkCDgMmAlea2d1AITCc2B876XjmVASUdnPNAL4I2szMrnP3jaFltv+KgNrAf5nZKqAL0BjoDqwwszvcfVuI+R2QYAWCPsAod59kZvWBv5nZDHe/MF3PnMzsOGK9Lb3d/X0zuwg4OeS0UkrXmJLjbWAW/PuHJxdoDdQP2g4JL7UqMQf42t3nAQuBq4D6HpOORQngFWCAmT0NPOTuvYj9QbGV2Ez3aSc40xtPrPvuReAxd/8l8DCxKb5+EGJ6B8zdi4l1UZa+3+zupwBNzezBoC2tilKgNnCfu78fvH8P6GxmrbLlOpMKUxK4e7G7bw7eGrAJ2ODu683sUuB2M6sdWoIHbjvQ1swGECtKY4DDzGxQuGntP3f/CLgZOBE4PGhbQWzWkcYhpnZA3H0GcCbwOsEvcXd/BahH7I+ltGNmP4x7+xUw1MwOi2vrDhySbuu3lX4vd38DmBm0VSc2R+g3wPfBWWCb8LJMDXXlJZm7FwFbzexLM7sD+BlwhbtHeYmOfXL3NWb2JfBb4Bp3/z8zOx1YHnJqB+o5YmdJI83si6DtOGKFN225+0YzewW42Mx2ErtmcTjwQbiZVV5w7WWamc11957u/qSZtQX+aWad3X2Vu39rZkXEim9aKOd7rQ8GFBWb2Q5ifyCVLv9zkZn1SdPu5YRo8EOSBafeNYClwfNP3D3tR0WZWSugibu/G7xP61F58YLRUBcS64J93N0/DDmlA2ZmDYDLgQuAHcCQuK6itBDcYzaTWDf5yUBu0OWKmf0vcC5wH9AIuAz4ubt/HlK6CSvne+W4+2XBZ9WJ9bpMAb4HjgUud/ePw8k2NVSYUsTMrgAWpPlEtHtIx4vL2czM6hH7ud9c4cYRFIyY3EzsrO8BYFdcceoOHAp0BP4UdM+mhXK+147S4hR8/lfgh0B3d18WSpIppMKUIvoFLlK1gkFEE4jd59PLzNoBW939iwp2jbS477Xd3S8Lrin1BZ7M9DOlUipMIpK2zKwR8P+IdYFVB7q4++pwszpwcd+rc9B0qrt/E2JKKaVReSKSttz9W2KDOA4i1s2V9kUJdvte9YELsqkogQqTiKQxM2sI/Bz4WSYMUimVqd8rUerKE5G0Zma1MmF6pbIy9XslQoVJREQiRV15IiISKSpMIiISKSpMIiISKSpMIiISKSpMIiISKSpMIiISKSpMIiISKSpMIkliZkea2YZgGQ3MrLmZfWtmXcLNTCTadIOtSBIFq/zeSGwphtnAh+5+c7hZiUSbCpNIkpnZXGIrxjrwY3cvDDklkUhTV55I8j0EtAf+rKIkUjGdMYkkkZnVBd4H5gPnAD9y9w3hZiUSbSpMIklkZo8A9dz9YjObADRw94vDzkskytSVJ5IkZtYNOBu4Kmi6ETjezC4NLyuR6NMZk4iIRIrOmEREJFJUmEREJFJUmEREJFJUmEREJFJUmEREJFJUmEREJFJUmEREJFJUmEREJFJUmEREJFJUmEREJFJywk5ApKosWrTorJycnNvc/VD0R1ciioF/FBUVDejYsePOsJMRKaXCJBlh0aJFZ+Xm5v4lPz9/Z+3atTdWq1ZNk0BWoKSkxL744otTNm3adDVwT9j5iJTSX5WSEXJycm7Lz8/fmZeXt11FKTHVqlXz5s2bb61evfoVYeciEk+FSTKCux9au3btHWHnkW5q1qy5y90PCjsPkXgqTJIpqulMqfLMDPR7QCJG/yBFRCRSVJhERCRSNCpPMlb+sGc7JvP4K8d0fbcy2z/wwAMH/+Uvf2m6YsWKWnl5ecVHHXXU9hEjRqw966yztiYrRzPr+OGHH37Uvn37wmTFEKlqOmMSSYGRI0c2HT58eKtbbrll7ddff/3+6tWrP7zqqqvWzZo1q0HYuYlEjQqTSJJ999131e+6667mY8eOXdWnT59N9evXL8nNzfVLLrnk+wcffHD19u3brV+/fq2aNGnSoUmTJh369evXavv27QYwfvz4Qzp27Ng2/nhm1vGjjz7KBbjgggvye/fufViXLl1+kJeXd1yHDh3+a8mSJbkAnTp1agvw4x//+Og6deoc99BDDzVM9XcX2R8qTCJJNn/+/LydO3dW692798byPr/11lubvfvuu3nvvffex4sXL/74vffeyxs2bFizRI8/d+7cg2+77bY1mzZtei8/P79w6NChLQAWLly4DGDBggUfFxQUvDdgwIBy44tEjQqTSJKtX78+p0GDBkU1atQo9/OZM2cePHz48LUtWrQoat68edFvfvObNTNmzDgk0eOfffbZG08//fSCGjVqcOmll25YsmRJ7SpLXiQEKkwiSda4ceOiTZs25ezatavcz9evX1/zyCOP/PfghCOOOGLnunXryq9i5WjatOm/D5yXl1dSUFBQ/YASFgmZCpNIkp1++unbatasWfLkk0+We42ncePGOz/77LPc0veff/55zSZNmuwCqFu3bsn27dv//XO6atUqjaSVjKfCJJJkhxxySPGQIUPW3HzzzYdNmjSpwZYtW6oVFhbatGnT6l911VUtu3fvvmHMmDHN1qxZk7N27dqc0aNHN7vgggu+A+jUqVPB8uXLa7/xxhu1CwoKbNiwYc0rGbvok08+ya14S5Ho0F9fkrEqe59RMo0cOfKbpk2b7rrzzjubDRw48PC8vLyS9u3bbxsxYsTazp07F/zqV7+qfswxxxwN0LVr141jxoxZC9ChQ4fCG264YU3Xrl1/mJub67/73e9WT5kypXGicYcMGbJm0KBB+X369Kn2xz/+8Ysrr7xSAyAk8sxd04tJ+nv//fdXHnPMMd+GnUc6ev/99xsdc8wx+WHnIVJKXXkiIhIpKkwiIhIpKkwiIhIpKkySKUpKSkos7CTSTXCNuSTsPETiqTBJRjCzr7dv314r7DzSzc6dO2uY2fdh5yEST4VJMkJRUdHvV65cWXPbtm21deaUmJKSEluzZk3d4uLix8PORSSehotLxli0aNFZOTk5t7n7oeiPrkQUA/8oKioa0LFjx51hJyNSSoVJREQiRX9ViohIpKgwiYhIpKgwiYhIpKgwiYhIpKgwiYhIpPx/he4OJEiztDAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the distinct rt intervals are ['(-inf, 3.44)' '[3.44, 4.58)' '[4.58, inf)']\n"
     ]
    }
   ],
   "source": [
    "data_bin = data_prep.bin_retention_time(data,'retention_time',variable = 'retention_time', bin_method = \"cart\", min_diff = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bcc57cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have passed cv!\n",
      "Cleanlab found 40 potential label errors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "data_confirmed, data_suspicious = data_prep.mislabeled_handling(data_bin, clf)\n",
    "data_confirmed = data_confirmed.drop(['retention_time_cat'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc4c9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/MultiRT/classifier_based_version/hilic_data_raw.csv\", index = False)\n",
    "data_confirmed.to_csv(\"data/MultiRT/classifier_based_version/hilic_data_confirmed.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db777a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_prep.make_train_test(data_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9af8276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"feature_engineered_models_mean\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"feature_engineered_models_mean\\\"\n",
      "AutoGluon Version:  0.4.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Windows\n",
      "Train Data Rows:    638\n",
      "Train Data Columns: 1330\n",
      "Label Column: retention_time\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (11.588571428571427, 1.0871428571428572, 2.53283, 1.63377)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6017.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 6.99 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 56 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 188): ['Column', 'nBridgehead', 'nB', 'nBr', 'nI', 'NsLi', 'NssBe', 'NssssBe', 'NssBH', 'NsssB', 'NssssB', 'NddC', 'NsNH3', 'NssNH2', 'NsssNH', 'NssssN', 'NaaO', 'NsSiH3', 'NssSiH2', 'NsssSiH', 'NssssSi', 'NsPH2', 'NssPH', 'NsssP', 'NsssssP', 'NsGeH3', 'NssGeH2', 'NsssGeH', 'NssssGe', 'NsAsH2', 'NssAsH', 'NsssAs', 'NsssdAs', 'NsssssAs', 'NsSeH', 'NdSe', 'NssSe', 'NaaSe', 'NdssSe', 'NddssSe', 'NsBr', 'NsSnH3', 'NssSnH2', 'NsssSnH', 'NssssSn', 'NsI', 'NsPbH3', 'NssPbH2', 'NsssPbH', 'NssssPb', 'SsLi', 'SssBe', 'SssssBe', 'SssBH', 'SsssB', 'SssssB', 'SddC', 'SsNH3', 'SssNH2', 'SsssNH', 'SssssN', 'SaaO', 'SsSiH3', 'SssSiH2', 'SsssSiH', 'SssssSi', 'SsPH2', 'SssPH', 'SsssP', 'SsssssP', 'SsGeH3', 'SssGeH2', 'SsssGeH', 'SssssGe', 'SsAsH2', 'SssAsH', 'SsssAs', 'SsssdAs', 'SsssssAs', 'SsSeH', 'SdSe', 'SssSe', 'SaaSe', 'SdssSe', 'SddssSe', 'SsBr', 'SsSnH3', 'SssSnH2', 'SsssSnH', 'SssssSn', 'SsI', 'SsPbH3', 'SssPbH2', 'SsssPbH', 'SssssPb', 'ETA_dPsi_B', 'SMR_VSA8', 'SlogP_VSA9', 'n4Ring', 'n8Ring', 'n9Ring', 'n10Ring', 'n11Ring', 'n12Ring', 'nG12Ring', 'n3HRing', 'n4HRing', 'n8HRing', 'n9HRing', 'n10HRing', 'n11HRing', 'n12HRing', 'nG12HRing', 'n3aRing', 'n4aRing', 'n7aRing', 'n8aRing', 'n9aRing', 'n10aRing', 'n11aRing', 'n12aRing', 'nG12aRing', 'n3aHRing', 'n4aHRing', 'n7aHRing', 'n8aHRing', 'n9aHRing', 'n10aHRing', 'n11aHRing', 'n12aHRing', 'nG12aHRing', 'n4ARing', 'n8ARing', 'n9ARing', 'n10ARing', 'n11ARing', 'n12ARing', 'nG12ARing', 'n3AHRing', 'n4AHRing', 'n8AHRing', 'n9AHRing', 'n10AHRing', 'n11AHRing', 'n12AHRing', 'nG12AHRing', 'n4FRing', 'n5FRing', 'n6FRing', 'n7FRing', 'n8FRing', 'n11FRing', 'n12FRing', 'n4FHRing', 'n5FHRing', 'n6FHRing', 'n7FHRing', 'n8FHRing', 'n11FHRing', 'n12FHRing', 'n4FaRing', 'n5FaRing', 'n6FaRing', 'n7FaRing', 'n8FaRing', 'n11FaRing', 'n12FaRing', 'n4FaHRing', 'n5FaHRing', 'n6FaHRing', 'n7FaHRing', 'n8FaHRing', 'n11FaHRing', 'n12FaHRing', 'n4FARing', 'n5FARing', 'n6FARing', 'n7FARing', 'n8FARing', 'n11FARing', 'n12FARing', 'n4FAHRing', 'n5FAHRing', 'n6FAHRing', 'n7FAHRing', 'n8FAHRing', 'n11FAHRing', 'n12FAHRing']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1138 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('object', []) :    4 | ['Compound_name', 'Organic_modifier', 'Buffer', 'SMILES']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "\t\t('float', [])     : 1084 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "\t\t('int', ['bool']) :   56 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "\t1.0s = Fit runtime\n",
      "\t1142 features in original data used to generate 1142 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 5.57 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 510, Val Rows: 128\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t-1.2582\t = Validation score   (root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t-1.2654\t = Validation score   (root_mean_squared_error)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t-0.9154\t = Validation score   (root_mean_squared_error)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.874588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.8725\t = Validation score   (root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000]\tvalid_set's rmse: 0.873073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t6.36s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ...\n",
      "\t-0.8789\t = Validation score   (root_mean_squared_error)\n",
      "\t3.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t-0.8693\t = Validation score   (root_mean_squared_error)\n",
      "\t77.97s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ...\n",
      "\t-0.9516\t = Validation score   (root_mean_squared_error)\n",
      "\t1.47s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 7: early stopping\n",
      "\t-1.2826\t = Validation score   (root_mean_squared_error)\n",
      "\t4.1s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t-0.8352\t = Validation score   (root_mean_squared_error)\n",
      "\t9.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t-1.2416\t = Validation score   (root_mean_squared_error)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_set's rmse: 0.857497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.8567\t = Validation score   (root_mean_squared_error)\n",
      "\t25.86s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t-0.8317\t = Validation score   (root_mean_squared_error)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 138.88s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"feature_engineered_models_mean\\\")\n",
      "Evaluation: root_mean_squared_error on test data: -0.3063567059144597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                  model  score_val  pred_time_val   fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0   WeightedEnsemble_L2  -0.831694       0.042010  42.256819                0.000000           0.208050            2       True         12\n",
      "1               XGBoost  -0.835219       0.014002   9.838072                0.014002           9.838072            1       True          9\n",
      "2         LightGBMLarge  -0.856685       0.014004  25.855382                0.014004          25.855382            1       True         11\n",
      "3              CatBoost  -0.869259       0.037537  77.965412                0.037537          77.965412            1       True          6\n",
      "4              LightGBM  -0.872476       0.014003   6.355314                0.014003           6.355314            1       True          4\n",
      "5       RandomForestMSE  -0.878853       0.036009   3.733844                0.036009           3.733844            1       True          5\n",
      "6            LightGBMXT  -0.915380       0.011003   2.406928                0.011003           2.406928            1       True          3\n",
      "7         ExtraTreesMSE  -0.951616       0.035008   1.474535                0.035008           1.474535            1       True          7\n",
      "8        NeuralNetTorch  -1.241649       0.218049   3.096037                0.218049           3.096037            1       True         10\n",
      "9        KNeighborsUnif  -1.258176       0.033005   0.106025                0.033005           0.106025            1       True          1\n",
      "10       KNeighborsDist  -1.265435       0.020004   0.161037                0.020004           0.161037            1       True          2\n",
      "11      NeuralNetFastAI  -1.282585       0.446954   4.096658                0.446954           4.096658            1       True          8\n",
      "Number of models trained: 12\n",
      "Types of models trained:\n",
      "{'LGBModel', 'XTModel', 'RFModel', 'KNNModel', 'TabularNeuralNetTorchModel', 'XGBoostModel', 'CatBoostModel', 'NNFastAiTabularModel', 'WeightedEnsembleModel'}\n",
      "Bagging used: False \n",
      "Multi-layer stack-ensembling used: False \n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', [])  :    2 | ['Compound_name', 'SMILES']\n",
      "('float', [])     : 1084 | ['pH', 'ABC', 'ABCGG', 'nAcid', 'nBase', ...]\n",
      "('int', ['bool']) :   56 | ['Organic_modifier', 'Buffer', 'nSpiro', 'nP', 'nBondsT', ...]\n",
      "*** End of fit() summary ***\n",
      "{'model_types': {'KNeighborsUnif': 'KNNModel', 'KNeighborsDist': 'KNNModel', 'LightGBMXT': 'LGBModel', 'LightGBM': 'LGBModel', 'RandomForestMSE': 'RFModel', 'CatBoost': 'CatBoostModel', 'ExtraTreesMSE': 'XTModel', 'NeuralNetFastAI': 'NNFastAiTabularModel', 'XGBoost': 'XGBoostModel', 'NeuralNetTorch': 'TabularNeuralNetTorchModel', 'LightGBMLarge': 'LGBModel', 'WeightedEnsemble_L2': 'WeightedEnsembleModel'}, 'model_performance': {'KNeighborsUnif': -1.2581759986109027, 'KNeighborsDist': -1.2654350894512154, 'LightGBMXT': -0.9153802836879098, 'LightGBM': -0.8724757914151119, 'RandomForestMSE': -0.878853197821241, 'CatBoost': -0.8692590408995589, 'ExtraTreesMSE': -0.9516162787476347, 'NeuralNetFastAI': -1.282584819553669, 'XGBoost': -0.835218869993004, 'NeuralNetTorch': -1.2416494580465411, 'LightGBMLarge': -0.8566847497621745, 'WeightedEnsemble_L2': -0.831694003124688}, 'model_best': 'WeightedEnsemble_L2', 'model_paths': {'KNeighborsUnif': 'feature_engineered_models_mean\\\\models\\\\KNeighborsUnif\\\\', 'KNeighborsDist': 'feature_engineered_models_mean\\\\models\\\\KNeighborsDist\\\\', 'LightGBMXT': 'feature_engineered_models_mean\\\\models\\\\LightGBMXT\\\\', 'LightGBM': 'feature_engineered_models_mean\\\\models\\\\LightGBM\\\\', 'RandomForestMSE': 'feature_engineered_models_mean\\\\models\\\\RandomForestMSE\\\\', 'CatBoost': 'feature_engineered_models_mean\\\\models\\\\CatBoost\\\\', 'ExtraTreesMSE': 'feature_engineered_models_mean\\\\models\\\\ExtraTreesMSE\\\\', 'NeuralNetFastAI': 'feature_engineered_models_mean\\\\models\\\\NeuralNetFastAI\\\\', 'XGBoost': 'feature_engineered_models_mean\\\\models\\\\XGBoost\\\\', 'NeuralNetTorch': 'feature_engineered_models_mean\\\\models\\\\NeuralNetTorch\\\\', 'LightGBMLarge': 'feature_engineered_models_mean\\\\models\\\\LightGBMLarge\\\\', 'WeightedEnsemble_L2': 'feature_engineered_models_mean\\\\models\\\\WeightedEnsemble_L2\\\\'}, 'model_fit_times': {'KNeighborsUnif': 0.10602521896362305, 'KNeighborsDist': 0.16103696823120117, 'LightGBMXT': 2.4069275856018066, 'LightGBM': 6.355314493179321, 'RandomForestMSE': 3.73384428024292, 'CatBoost': 77.96541237831116, 'ExtraTreesMSE': 1.4745352268218994, 'NeuralNetFastAI': 4.09665846824646, 'XGBoost': 9.838072299957275, 'NeuralNetTorch': 3.0960373878479004, 'LightGBMLarge': 25.855382442474365, 'WeightedEnsemble_L2': 0.20805025100708008}, 'model_pred_times': {'KNeighborsUnif': 0.033005475997924805, 'KNeighborsDist': 0.0200042724609375, 'LightGBMXT': 0.011002779006958008, 'LightGBM': 0.014003276824951172, 'RandomForestMSE': 0.03600931167602539, 'CatBoost': 0.03753662109375, 'ExtraTreesMSE': 0.03500843048095703, 'NeuralNetFastAI': 0.44695448875427246, 'XGBoost': 0.014002084732055664, 'NeuralNetTorch': 0.2180488109588623, 'LightGBMLarge': 0.014004230499267578, 'WeightedEnsemble_L2': 0.0}, 'num_bag_folds': 0, 'max_stack_level': 2, 'model_hyperparams': {'KNeighborsUnif': {'weights': 'uniform'}, 'KNeighborsDist': {'weights': 'distance'}, 'LightGBMXT': {'learning_rate': 0.05, 'extra_trees': True}, 'LightGBM': {'learning_rate': 0.05}, 'RandomForestMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'CatBoost': {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE'}, 'ExtraTreesMSE': {'n_estimators': 300, 'n_jobs': -1, 'random_state': 0, 'bootstrap': True, 'criterion': 'squared_error'}, 'NeuralNetFastAI': {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}, 'XGBoost': {'n_estimators': 10000, 'learning_rate': 0.1, 'n_jobs': -1, 'proc.max_category_levels': 100, 'objective': 'reg:squarederror', 'booster': 'gbtree'}, 'NeuralNetTorch': {'num_epochs': 500, 'epochs_wo_improve': 20, 'activation': 'relu', 'embedding_size_factor': 1.0, 'embed_exponent': 0.56, 'max_embedding_dim': 100, 'y_range': None, 'y_range_extend': 0.05, 'dropout_prob': 0.1, 'optimizer': 'adam', 'learning_rate': 0.0003, 'weight_decay': 1e-06, 'proc.embed_min_categories': 4, 'proc.impute_strategy': 'median', 'proc.max_category_levels': 100, 'proc.skew_threshold': 0.99, 'use_ngram_features': False, 'num_layers': 4, 'hidden_size': 128, 'max_batch_size': 512, 'use_batchnorm': False, 'loss_function': 'auto'}, 'LightGBMLarge': {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5}, 'WeightedEnsemble_L2': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}}, 'leaderboard':                   model  score_val  pred_time_val   fit_time  \\\n",
      "0   WeightedEnsemble_L2  -0.831694       0.042010  42.256819   \n",
      "1               XGBoost  -0.835219       0.014002   9.838072   \n",
      "2         LightGBMLarge  -0.856685       0.014004  25.855382   \n",
      "3              CatBoost  -0.869259       0.037537  77.965412   \n",
      "4              LightGBM  -0.872476       0.014003   6.355314   \n",
      "5       RandomForestMSE  -0.878853       0.036009   3.733844   \n",
      "6            LightGBMXT  -0.915380       0.011003   2.406928   \n",
      "7         ExtraTreesMSE  -0.951616       0.035008   1.474535   \n",
      "8        NeuralNetTorch  -1.241649       0.218049   3.096037   \n",
      "9        KNeighborsUnif  -1.258176       0.033005   0.106025   \n",
      "10       KNeighborsDist  -1.265435       0.020004   0.161037   \n",
      "11      NeuralNetFastAI  -1.282585       0.446954   4.096658   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000000           0.208050            2       True   \n",
      "1                 0.014002           9.838072            1       True   \n",
      "2                 0.014004          25.855382            1       True   \n",
      "3                 0.037537          77.965412            1       True   \n",
      "4                 0.014003           6.355314            1       True   \n",
      "5                 0.036009           3.733844            1       True   \n",
      "6                 0.011003           2.406928            1       True   \n",
      "7                 0.035008           1.474535            1       True   \n",
      "8                 0.218049           3.096037            1       True   \n",
      "9                 0.033005           0.106025            1       True   \n",
      "10                0.020004           0.161037            1       True   \n",
      "11                0.446954           4.096658            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          12  \n",
      "1           9  \n",
      "2          11  \n",
      "3           6  \n",
      "4           4  \n",
      "5           5  \n",
      "6           3  \n",
      "7           7  \n",
      "8          10  \n",
      "9           1  \n",
      "10          2  \n",
      "11          8  }\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.3063567059144597,\n",
      "    \"mean_squared_error\": -0.09385443125875878,\n",
      "    \"mean_absolute_error\": -0.13149278466337916,\n",
      "    \"r2\": 0.9226974588855721,\n",
      "    \"pearsonr\": 0.9609640892114772,\n",
      "    \"median_absolute_error\": -0.029589683668954092\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'root_mean_squared_error': -0.3063567059144597, 'mean_squared_error': -0.09385443125875878, 'mean_absolute_error': -0.13149278466337916, 'r2': 0.9226974588855721, 'pearsonr': 0.9609640892114772, 'median_absolute_error': -0.029589683668954092}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x2f927dd9370>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap.autogluon_fit_train_test (train, test, 'feature_engineered_models_mean') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
